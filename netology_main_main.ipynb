{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef289504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, classification_report, precision_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from boruta import BorutaPy\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7d808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dataset_train.csv')\n",
    "test = pd.read_csv('test_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3219421",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf117a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_indicator</th>\n",
       "      <th>month_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>carts_created_at</th>\n",
       "      <th>spent_time_total</th>\n",
       "      <th>spent_time_to_complete_hw</th>\n",
       "      <th>completed_hw</th>\n",
       "      <th>failed_hw</th>\n",
       "      <th>reworked_hw</th>\n",
       "      <th>interacted_hw</th>\n",
       "      <th>avg_hw_mark</th>\n",
       "      <th>test_with_good_mark</th>\n",
       "      <th>test_with_great_mark</th>\n",
       "      <th>webinars</th>\n",
       "      <th>avg_quiz_result</th>\n",
       "      <th>notes</th>\n",
       "      <th>hw_leader</th>\n",
       "      <th>lessons</th>\n",
       "      <th>activity</th>\n",
       "      <th>bought_d1</th>\n",
       "      <th>bought_d2</th>\n",
       "      <th>bought_d3</th>\n",
       "      <th>bought_d4</th>\n",
       "      <th>bought_d5</th>\n",
       "      <th>bought_avg_duration</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>promo</th>\n",
       "      <th>price</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>auto_payment</th>\n",
       "      <th>ABC</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>speed_recall</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>platform</th>\n",
       "      <th>m_avg_talk_duration</th>\n",
       "      <th>m_avg_duration</th>\n",
       "      <th>m_missed_calls</th>\n",
       "      <th>m_total_calls</th>\n",
       "      <th>m_was_conversations</th>\n",
       "      <th>m_total_duration</th>\n",
       "      <th>p_avg_talk_duration</th>\n",
       "      <th>p_avg_duration</th>\n",
       "      <th>p_missed_calls</th>\n",
       "      <th>p_total_calls</th>\n",
       "      <th>p_was_conversations</th>\n",
       "      <th>p_total_duration</th>\n",
       "      <th>support_feedback_avg</th>\n",
       "      <th>feedback_avg_d1</th>\n",
       "      <th>feedback_avg_d2</th>\n",
       "      <th>feedback_avg_d3</th>\n",
       "      <th>feedback_avg_d4</th>\n",
       "      <th>feedback_avg_d5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15182</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9/30/2020</td>\n",
       "      <td>6694527</td>\n",
       "      <td>1469</td>\n",
       "      <td>8/26/2020</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>20042.959300</td>\n",
       "      <td>phone</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2021</td>\n",
       "      <td>6712877</td>\n",
       "      <td>1392</td>\n",
       "      <td>8/5/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>15057.315000</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/28/2021</td>\n",
       "      <td>6659444</td>\n",
       "      <td>376</td>\n",
       "      <td>6/20/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>23389.029300</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/30/2021</td>\n",
       "      <td>7151591</td>\n",
       "      <td>1160</td>\n",
       "      <td>4/14/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>22260.632220</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7806</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10/31/2020</td>\n",
       "      <td>6705666</td>\n",
       "      <td>952</td>\n",
       "      <td>7/19/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>7255.515915</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>179932</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11/30/2021</td>\n",
       "      <td>6816668</td>\n",
       "      <td>1043</td>\n",
       "      <td>10/16/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>10263.967450</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>257734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/30/2021</td>\n",
       "      <td>6984939</td>\n",
       "      <td>1635</td>\n",
       "      <td>1/2/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>35998.565400</td>\n",
       "      <td>order</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iOS</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>43549</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3/31/2021</td>\n",
       "      <td>6670084</td>\n",
       "      <td>789</td>\n",
       "      <td>6/29/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>22084.062000</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>100800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2021</td>\n",
       "      <td>6917324</td>\n",
       "      <td>476</td>\n",
       "      <td>12/7/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>14377.805400</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>Samsung Internet</td>\n",
       "      <td>mobile</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>162913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10/31/2021</td>\n",
       "      <td>7057970</td>\n",
       "      <td>1104</td>\n",
       "      <td>2/24/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>55596.240000</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mac OS X</td>\n",
       "      <td>Safari</td>\n",
       "      <td>pc</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age_indicator    month_id  student_id  program_id  \\\n",
       "0        15182           32.0   9/30/2020     6694527        1469   \n",
       "1        89385            NaN   6/30/2021     6712877        1392   \n",
       "2        47931            NaN   2/28/2021     6659444         376   \n",
       "3       279085            1.0  11/30/2021     7151591        1160   \n",
       "4         7806           30.0  10/31/2020     6705666         952   \n",
       "...        ...            ...         ...         ...         ...   \n",
       "199995  179932           27.0  11/30/2021     6816668        1043   \n",
       "199996  257734            NaN   9/30/2021     6984939        1635   \n",
       "199997   43549           17.0   3/31/2021     6670084         789   \n",
       "199998  100800            NaN   6/30/2021     6917324         476   \n",
       "199999  162913           18.0  10/31/2021     7057970        1104   \n",
       "\n",
       "       carts_created_at  spent_time_total  spent_time_to_complete_hw  \\\n",
       "0             8/26/2020             163.0                        0.0   \n",
       "1              8/5/2020               NaN                        NaN   \n",
       "2             6/20/2020               NaN                        NaN   \n",
       "3             4/14/2021               NaN                        NaN   \n",
       "4             7/19/2020               NaN                        NaN   \n",
       "...                 ...               ...                        ...   \n",
       "199995       10/16/2020               NaN                        NaN   \n",
       "199996         1/2/2021               NaN                        NaN   \n",
       "199997        6/29/2020               NaN                        NaN   \n",
       "199998        12/7/2020               NaN                        NaN   \n",
       "199999        2/24/2021               NaN                        NaN   \n",
       "\n",
       "        completed_hw  failed_hw  reworked_hw  interacted_hw  avg_hw_mark  \\\n",
       "0                1.0        0.0         17.0            3.0        100.0   \n",
       "1                NaN        NaN          NaN            NaN          NaN   \n",
       "2                NaN        NaN          NaN            NaN          NaN   \n",
       "3                NaN        NaN          NaN            NaN          NaN   \n",
       "4                NaN        NaN          NaN            NaN          NaN   \n",
       "...              ...        ...          ...            ...          ...   \n",
       "199995           NaN        NaN          NaN            NaN          NaN   \n",
       "199996           NaN        NaN          NaN            NaN          NaN   \n",
       "199997           0.0        0.0          0.0            2.0          NaN   \n",
       "199998           NaN        NaN          NaN            NaN          NaN   \n",
       "199999           NaN        NaN          NaN            NaN          NaN   \n",
       "\n",
       "        test_with_good_mark  test_with_great_mark  webinars  avg_quiz_result  \\\n",
       "0                      12.0                   8.0       0.0              NaN   \n",
       "1                       NaN                   NaN       NaN              NaN   \n",
       "2                       NaN                   NaN       NaN              NaN   \n",
       "3                       NaN                   NaN       NaN              NaN   \n",
       "4                       NaN                   NaN       NaN              NaN   \n",
       "...                     ...                   ...       ...              ...   \n",
       "199995                  NaN                   NaN       NaN              NaN   \n",
       "199996                  NaN                   NaN       NaN              NaN   \n",
       "199997                  0.0                   0.0       0.0              NaN   \n",
       "199998                  NaN                   NaN       NaN              NaN   \n",
       "199999                  NaN                   NaN       NaN              NaN   \n",
       "\n",
       "        notes  hw_leader  lessons  activity  bought_d1  bought_d2  bought_d3  \\\n",
       "0       147.0        0.0     14.0      32.0          0          0          0   \n",
       "1         NaN        NaN      NaN       NaN          0          0          0   \n",
       "2         NaN        NaN      NaN       NaN          0          0          0   \n",
       "3         NaN        NaN      NaN       NaN          0          0          0   \n",
       "4         NaN        NaN      NaN       NaN          0          0          0   \n",
       "...       ...        ...      ...       ...        ...        ...        ...   \n",
       "199995    NaN        NaN      NaN       NaN          1          0          0   \n",
       "199996    NaN        NaN      NaN       NaN          0          0          0   \n",
       "199997    0.0        0.0      2.0       0.0          0          0          0   \n",
       "199998    NaN        NaN      NaN       NaN          0          0          0   \n",
       "199999    NaN        NaN      NaN       NaN          0          0          0   \n",
       "\n",
       "        bought_d4  bought_d5  bought_avg_duration  payment_type promo  \\\n",
       "0               0          0                  NaN             1     +   \n",
       "1               0          0                  NaN             1     -   \n",
       "2               0          0                  NaN             1     +   \n",
       "3               0          0                  NaN             1     -   \n",
       "4               0          0                  NaN             1     -   \n",
       "...           ...        ...                  ...           ...   ...   \n",
       "199995          1          0                 40.0             1     +   \n",
       "199996          0          0                  NaN             1     -   \n",
       "199997          0          0                  NaN             1     +   \n",
       "199998          0          0                  NaN             1     -   \n",
       "199999          0          0                  NaN             1     -   \n",
       "\n",
       "               price communication_type  auto_payment ABC city country  \\\n",
       "0       20042.959300              phone             0   D  NaN     NaN   \n",
       "1       15057.315000              order             1   A  NaN     NaN   \n",
       "2       23389.029300                web             0   D  NaN     NaN   \n",
       "3       22260.632220              order             1   B  NaN     NaN   \n",
       "4        7255.515915              order             1   A  NaN     NaN   \n",
       "...              ...                ...           ...  ..  ...     ...   \n",
       "199995  10263.967450              order             1   D  NaN     NaN   \n",
       "199996  35998.565400              order             0   D  NaN     NaN   \n",
       "199997  22084.062000                web             0   D  NaN     NaN   \n",
       "199998  14377.805400              order             1   A  NaN     NaN   \n",
       "199999  55596.240000              order             1   A  NaN     NaN   \n",
       "\n",
       "        gender  speed_recall        os           browser platform  \\\n",
       "0          1.0           NaN       NaN               NaN      NaN   \n",
       "1          0.0           1.0       NaN               NaN      NaN   \n",
       "2          0.0           NaN       NaN               NaN      NaN   \n",
       "3          1.0           NaN   Windows            Chrome       pc   \n",
       "4          1.0           NaN       NaN               NaN      NaN   \n",
       "...        ...           ...       ...               ...      ...   \n",
       "199995     1.0           NaN       NaN               NaN      NaN   \n",
       "199996     0.0           NaN       iOS     Mobile Safari   mobile   \n",
       "199997     1.0           NaN       NaN               NaN      NaN   \n",
       "199998     0.0           NaN   Android  Samsung Internet   mobile   \n",
       "199999     1.0           NaN  Mac OS X            Safari       pc   \n",
       "\n",
       "        m_avg_talk_duration  m_avg_duration  m_missed_calls  m_total_calls  \\\n",
       "0                       NaN             NaN             NaN            NaN   \n",
       "1                       NaN             NaN             NaN            NaN   \n",
       "2                       NaN             NaN             NaN            NaN   \n",
       "3                       NaN             NaN             NaN            NaN   \n",
       "4                       NaN             NaN             NaN            NaN   \n",
       "...                     ...             ...             ...            ...   \n",
       "199995                  0.0             NaN             3.0            3.0   \n",
       "199996                  NaN             NaN             NaN            NaN   \n",
       "199997                  NaN             NaN             NaN            NaN   \n",
       "199998                  6.0             6.0             0.0            1.0   \n",
       "199999                 69.5            69.5             0.0            2.0   \n",
       "\n",
       "        m_was_conversations  m_total_duration  p_avg_talk_duration  \\\n",
       "0                       NaN               NaN                  NaN   \n",
       "1                       NaN               NaN                  NaN   \n",
       "2                       NaN               NaN                  NaN   \n",
       "3                       NaN               NaN                  NaN   \n",
       "4                       NaN               NaN                  NaN   \n",
       "...                     ...               ...                  ...   \n",
       "199995                  0.0               0.0                  NaN   \n",
       "199996                  NaN               NaN                  NaN   \n",
       "199997                  NaN               NaN                  NaN   \n",
       "199998                  1.0               6.0                  NaN   \n",
       "199999                  2.0             139.0                  NaN   \n",
       "\n",
       "        p_avg_duration  p_missed_calls  p_total_calls  p_was_conversations  \\\n",
       "0                  NaN             NaN            NaN                  NaN   \n",
       "1                  NaN             NaN            NaN                  NaN   \n",
       "2                  NaN             NaN            NaN                  NaN   \n",
       "3                  NaN             NaN            NaN                  NaN   \n",
       "4                  NaN             NaN            NaN                  NaN   \n",
       "...                ...             ...            ...                  ...   \n",
       "199995             NaN             NaN            NaN                  NaN   \n",
       "199996             NaN             NaN            NaN                  NaN   \n",
       "199997             NaN             NaN            NaN                  NaN   \n",
       "199998             NaN             NaN            NaN                  NaN   \n",
       "199999             NaN             NaN            NaN                  NaN   \n",
       "\n",
       "        p_total_duration  support_feedback_avg  feedback_avg_d1  \\\n",
       "0                    NaN                   4.0              5.0   \n",
       "1                    NaN                   NaN              NaN   \n",
       "2                    NaN                   NaN              NaN   \n",
       "3                    NaN                   NaN              NaN   \n",
       "4                    NaN                   NaN              5.0   \n",
       "...                  ...                   ...              ...   \n",
       "199995               NaN                   5.0              NaN   \n",
       "199996               NaN                   NaN              4.5   \n",
       "199997               NaN                   3.0              NaN   \n",
       "199998               NaN                   NaN              NaN   \n",
       "199999               NaN                   NaN              NaN   \n",
       "\n",
       "        feedback_avg_d2  feedback_avg_d3  feedback_avg_d4  feedback_avg_d5  \\\n",
       "0                   NaN              NaN              NaN              NaN   \n",
       "1                   NaN              NaN              NaN              NaN   \n",
       "2                   NaN              NaN              NaN              NaN   \n",
       "3                   NaN              NaN              NaN              NaN   \n",
       "4                   NaN              NaN              NaN              NaN   \n",
       "...                 ...              ...              ...              ...   \n",
       "199995              NaN              NaN              NaN              NaN   \n",
       "199996              NaN              NaN              NaN              NaN   \n",
       "199997              NaN              NaN              4.0              NaN   \n",
       "199998              NaN              NaN              NaN              NaN   \n",
       "199999              NaN              NaN              NaN              NaN   \n",
       "\n",
       "        target  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "199995       0  \n",
       "199996       0  \n",
       "199997       0  \n",
       "199998       0  \n",
       "199999       0  \n",
       "\n",
       "[200000 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce654922",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39778efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательный флаг тренировочного и тестовой частей общего набора данных\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "# объединение в один датасет\n",
    "train = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2d0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# некоторые колонки с количественными переменными следует заполнить нулями,\n",
    "# а некоторые заполнить \"типичным\" значением\n",
    "cols_to_fill_with_zero = ['avg_quiz_result', 'bought_avg_duration', 'speed_recall', 'm_avg_talk_duration', 'm_avg_duration', \\\n",
    "                          'm_missed_calls', 'm_total_calls', 'm_was_conversations', 'm_total_duration', 'p_avg_talk_duration', \\\n",
    "                          'p_avg_duration', 'p_missed_calls', 'p_total_calls', 'p_was_conversations', 'p_total_duration', \\\n",
    "                          'support_feedback_avg', 'feedback_avg_d1', 'feedback_avg_d2', 'feedback_avg_d3', 'feedback_avg_d4', \\\n",
    "                          'feedback_avg_d5', 'avg_hw_mark']\n",
    "cols_to_fill_with_avg = ['age_indicator', 'spent_time_total', 'spent_time_to_complete_hw', 'completed_hw', \\\n",
    "                         'failed_hw', 'reworked_hw', 'interacted_hw', 'test_with_good_mark', \\\n",
    "                         'test_with_great_mark', 'webinars', 'notes', 'hw_leader', \\\n",
    "                         'lessons', 'activity', 'bought_d1', 'bought_d2', 'bought_d3', 'bought_d4', \\\n",
    "                         'bought_d5', 'price', 'gender']\n",
    "\n",
    "cols_to_fill_with_nan = ['communication_type', 'city', 'country', 'os', 'browser', 'platform']\n",
    "\n",
    "for i in cols_to_fill_with_zero:\n",
    "    train.fillna({i: 0}, inplace=True)\n",
    "\n",
    "for i in cols_to_fill_with_avg:\n",
    "    train.fillna({i: train[i].median()}, inplace=True)\n",
    "\n",
    "for i in cols_to_fill_with_nan:\n",
    "    train.fillna({i: 'None'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def3c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведём колонку в формат datetime и возьмём из неё только месяц\n",
    "train['month_id'] = pd.to_datetime(train['month_id'], format = \"%m/%d/%Y\")\n",
    "train['day_id'] = pd.DatetimeIndex(train['month_id']).day\n",
    "train['day_of_week_id'] = pd.DatetimeIndex(train['month_id']).day_of_week\n",
    "train['month_id'] = pd.DatetimeIndex(train['month_id']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23bb5243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2451815549.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train = train.drop(['carts_created_at'],1)\n"
     ]
    }
   ],
   "source": [
    "# переведём колонку в формат datetime\n",
    "train['carts_created_at'] = pd.to_datetime(train['carts_created_at'], format = \"%m/%d/%Y\")\n",
    "train['carts_created_at_month'] = pd.DatetimeIndex(train['carts_created_at']).month\n",
    "train['carts_created_at_day'] = pd.DatetimeIndex(train['carts_created_at']).day\n",
    "train['carts_created_at_day_of_week'] = pd.DatetimeIndex(train['carts_created_at']).day_of_week\n",
    "train = train.drop(['carts_created_at'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8853b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/44424804.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train = train.drop(['spent_time_to_complete_hw'], 1)\n"
     ]
    }
   ],
   "source": [
    "# удалим переменные не содержащие информации\n",
    "train = train.drop(['spent_time_to_complete_hw'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e682bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в нужный формат\n",
    "def promo(x):\n",
    "    if x == '+':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['promo'] = train['promo'].map(lambda x: promo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0852b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/1474686982.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = XY_train.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/1474686982.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = XY_val.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/1474686982.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = XY_test.drop(['target'], 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим выборки\n",
    "XY_train = train[train['train'] == 1].drop('train', axis=1)\n",
    "XY_test = train[train['train'] == 0].drop('train', axis=1)\n",
    "XY_train, XY_val = train_test_split(XY_train, test_size=0.2, random_state=23)\n",
    "\n",
    "X_train = XY_train.drop(['target'], 1)\n",
    "Y_train = XY_train['target']\n",
    "\n",
    "X_val = XY_val.drop(['target'], 1)\n",
    "Y_val = XY_val['target']\n",
    "\n",
    "X_test = XY_test.drop(['target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f170d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_vars = ['program_id', 'student_id', 'communication_type', 'ABC', 'city', 'country', 'os', 'browser', \\\n",
    "                   'platform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d9d19dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotTargetEncoder():\n",
    "    def __init__(self, class_names = None, target_encoders = {}):\n",
    "        self.target_encoders = target_encoders\n",
    "        self.class_names = class_names\n",
    "    def fit(self, X, y):\n",
    "        y=y.astype(str)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        y_onehot = pd.DataFrame(enc.fit_transform(pd.DataFrame(Y_train)).toarray())\n",
    "        self.class_names=y_onehot.columns\n",
    "        for class_ in self.class_names:\n",
    "            enc=ce.CatBoostEncoder()\n",
    "            enc.fit(X,y_onehot[class_]) #convert all categorical\n",
    "            self.target_encoders[class_] = enc\n",
    "    def transform(self, X):\n",
    "        X_obj=X\n",
    "        for class_ in self.class_names:\n",
    "            X_temp = self.target_encoders[class_].transform(X_obj)\n",
    "            X_temp.columns = [str(i)+'_'+str(class_) for i in X_temp.columns]\n",
    "            X = pd.concat([X,X_temp],axis=1)\n",
    "        return X.drop(X_obj.columns,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "25d9e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/218761128.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return X.drop(X_obj.columns,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2393891689.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = X_train.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2393891689.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = X_val.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2393891689.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(categorial_vars,1)\n"
     ]
    }
   ],
   "source": [
    "one_hot_target_encoder = OneHotTargetEncoder()\n",
    "\n",
    "one_hot_target_encoder.fit(X_train[categorial_vars], Y_train)\n",
    "\n",
    "X_train = pd.concat([X_train, one_hot_target_encoder.transform(X_train[categorial_vars])], axis=1)\n",
    "X_val = pd.concat([X_val, one_hot_target_encoder.transform(X_val[categorial_vars])], axis=1)\n",
    "X_test = pd.concat([X_test, one_hot_target_encoder.transform(X_test[categorial_vars])], axis=1)\n",
    "\n",
    "X_train = X_train.drop(categorial_vars,1)\n",
    "X_val = X_val.drop(categorial_vars,1)\n",
    "X_test = X_test.drop(categorial_vars,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b959d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Источник: stackoverflow\n",
    "# Feature selection class to eliminate multicollinearity\n",
    "# Выбор и удаление признаков скоррелированных между собой (борьба с мультиколлинеарносстью)\n",
    "class MultiCollinearityEliminator():\n",
    "\n",
    "    # Class initialisation\n",
    "    # Инициализация класса\n",
    "    def __init__(self, df, target, threshold=0.5):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # Method to create and return the feature correlation matrix dataframe\n",
    "    # Метод создающий и возращающий корреляционную матрицу признаков датафрейма\n",
    "    def createCorrMatrix(self, include_target=False):\n",
    "        # Checking we should include the target in the correlation matrix\n",
    "        if (include_target == False):\n",
    "            #df_temp = self.df.drop([self.target], axis=1)\n",
    "            df_temp = self.df\n",
    "\n",
    "            # Setting method to Pearson to prevent issues in case the default method for df.corr() gets changed\n",
    "            # Setting min_period to 30 for the sample size to be statistically significant (normal) according to\n",
    "            # central limit theorem\n",
    "            corrMatrix = df_temp.corr(method='pearson', min_periods=30).abs()\n",
    "\n",
    "        # Target is included for creating the series of feature to target correlation - Please refer the notes under the\n",
    "        # print statement to understand why we create the series of feature to target correlation\n",
    "        elif (include_target == True):\n",
    "            corrMatrix = self.df.corr(method='pearson', min_periods=30).abs()\n",
    "\n",
    "        return corrMatrix\n",
    "\n",
    "    # Method to create and return the feature to target correlation matrix dataframe\n",
    "    # Метод создающий и возвращающий корреляционную матрицу признаков с целевой переменной\n",
    "    def createCorrMatrixWithTarget(self):\n",
    "\n",
    "        # After obtaining the list of correlated features, this method will help to view which variables\n",
    "        # (in the list of correlated features) are least correlated with the target\n",
    "        # This way, out the list of correlated features, we can ensure to elimate the feature that is\n",
    "        # least correlated with the target\n",
    "        # This not only helps to sustain the predictive power of the model but also helps in reducing model complexity\n",
    "\n",
    "        # Obtaining the correlation matrix of the dataframe (along with the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target=True)\n",
    "\n",
    "        # Creating the required dataframe, then dropping the target row\n",
    "        # and sorting by the value of correlation with target (in asceding order)\n",
    "        corrWithTarget = pd.DataFrame(corrMatrix.loc[:, self.target]).drop(\n",
    "            [self.target], axis=0).sort_values(by=self.target)\n",
    "        #print(corrWithTarget, '\\n')\n",
    "        return corrWithTarget\n",
    "\n",
    "    # Method to create and return the list of correlated features\n",
    "    # Метод создающий и вовзращающий лист скоррелированных признаков\n",
    "    def createCorrelatedFeaturesList(self):\n",
    "        # Obtaining the correlation matrix of the dataframe (without the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target=False)\n",
    "        colCorr = []\n",
    "        # Iterating through the columns of the correlation matrix dataframe\n",
    "        for column in corrMatrix.columns:\n",
    "            # Iterating through the values (row wise) of the correlation matrix dataframe\n",
    "            for idx, row in corrMatrix.iterrows():\n",
    "                if(row[column] > self.threshold) and (row[column] < 1):\n",
    "                    # Adding the features that are not already in the list of correlated features\n",
    "                    if (idx not in colCorr):\n",
    "                        colCorr.append(idx)\n",
    "                    if (column not in colCorr):\n",
    "                        colCorr.append(column)\n",
    "        #print(colCorr, '\\n')\n",
    "        return colCorr\n",
    "\n",
    "    # Method to eliminate the least important features from the list of correlated features\n",
    "    # Метод удаляющий наименее важные признаки (наименее скоррелированные с целевым признаком) из двух скоррелированных признаков\n",
    "    def deleteFeatures(self, colCorr):\n",
    "        # Obtaining the feature to target correlation matrix dataframe\n",
    "        corrWithTarget = self.createCorrMatrixWithTarget()\n",
    "        for idx, row in corrWithTarget.iterrows():\n",
    "            #print(idx, '\\n')\n",
    "            if (idx in colCorr):\n",
    "                self.df = self.df.drop(idx, axis=1)\n",
    "                break\n",
    "        return self.df\n",
    "\n",
    "    # Method to run automatically eliminate multicollinearity\n",
    "    # Метод запускающий и удаляющий мультиколлинеарность\n",
    "    def autoEliminateMulticollinearity(self):\n",
    "        # Obtaining the list of correlated features\n",
    "        colCorr = self.createCorrelatedFeaturesList()\n",
    "        while colCorr != []:\n",
    "            # Obtaining the dataframe after deleting the feature (from the list of correlated features)\n",
    "            # that is least correlated with the taregt\n",
    "            self.df = self.deleteFeatures(colCorr)\n",
    "            # Obtaining the list of correlated features\n",
    "            colCorr = self.createCorrelatedFeaturesList()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1933cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/3721317429.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = corr_explorer.autoEliminateMulticollinearity().drop(['target'],1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/3721317429.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = X_val.drop(X_val.columns.difference(X_train.columns),1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/3721317429.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(X_test.columns.difference(X_train.columns),1)\n"
     ]
    }
   ],
   "source": [
    "# устраним скоррелированные признаки\n",
    "corr_explorer = MultiCollinearityEliminator(pd.concat([X_train, Y_train], axis=1), 'target', 0.75)\n",
    "\n",
    "X_train = corr_explorer.autoEliminateMulticollinearity().drop(['target'],1)\n",
    "\n",
    "X_val = X_val.drop(X_val.columns.difference(X_train.columns),1)\n",
    "X_test = X_test.drop(X_test.columns.difference(X_train.columns),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "776c7b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_indicator</th>\n",
       "      <th>month_id</th>\n",
       "      <th>spent_time_total</th>\n",
       "      <th>failed_hw</th>\n",
       "      <th>reworked_hw</th>\n",
       "      <th>avg_hw_mark</th>\n",
       "      <th>test_with_good_mark</th>\n",
       "      <th>webinars</th>\n",
       "      <th>avg_quiz_result</th>\n",
       "      <th>notes</th>\n",
       "      <th>hw_leader</th>\n",
       "      <th>activity</th>\n",
       "      <th>bought_d1</th>\n",
       "      <th>bought_d2</th>\n",
       "      <th>bought_d3</th>\n",
       "      <th>bought_d4</th>\n",
       "      <th>bought_d5</th>\n",
       "      <th>bought_avg_duration</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>promo</th>\n",
       "      <th>price</th>\n",
       "      <th>auto_payment</th>\n",
       "      <th>gender</th>\n",
       "      <th>speed_recall</th>\n",
       "      <th>m_avg_duration</th>\n",
       "      <th>m_total_calls</th>\n",
       "      <th>p_total_calls</th>\n",
       "      <th>p_was_conversations</th>\n",
       "      <th>p_total_duration</th>\n",
       "      <th>support_feedback_avg</th>\n",
       "      <th>feedback_avg_d1</th>\n",
       "      <th>feedback_avg_d2</th>\n",
       "      <th>feedback_avg_d3</th>\n",
       "      <th>feedback_avg_d4</th>\n",
       "      <th>feedback_avg_d5</th>\n",
       "      <th>day_id</th>\n",
       "      <th>day_of_week_id</th>\n",
       "      <th>carts_created_at_month</th>\n",
       "      <th>carts_created_at_day</th>\n",
       "      <th>carts_created_at_day_of_week</th>\n",
       "      <th>program_id_0</th>\n",
       "      <th>student_id_0</th>\n",
       "      <th>ABC_0</th>\n",
       "      <th>city_0</th>\n",
       "      <th>country_0</th>\n",
       "      <th>program_id_1</th>\n",
       "      <th>student_id_1</th>\n",
       "      <th>ABC_1</th>\n",
       "      <th>city_1</th>\n",
       "      <th>program_id_2</th>\n",
       "      <th>student_id_2</th>\n",
       "      <th>communication_type_2</th>\n",
       "      <th>city_2</th>\n",
       "      <th>country_2</th>\n",
       "      <th>os_2</th>\n",
       "      <th>browser_2</th>\n",
       "      <th>program_id_3</th>\n",
       "      <th>student_id_3</th>\n",
       "      <th>communication_type_3</th>\n",
       "      <th>city_3</th>\n",
       "      <th>country_3</th>\n",
       "      <th>program_id_4</th>\n",
       "      <th>student_id_4</th>\n",
       "      <th>city_4</th>\n",
       "      <th>country_4</th>\n",
       "      <th>browser_4</th>\n",
       "      <th>program_id_5</th>\n",
       "      <th>student_id_5</th>\n",
       "      <th>ABC_5</th>\n",
       "      <th>city_5</th>\n",
       "      <th>country_5</th>\n",
       "      <th>os_5</th>\n",
       "      <th>browser_5</th>\n",
       "      <th>platform_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83245</th>\n",
       "      <td>151631</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35385.97720</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122826</th>\n",
       "      <td>183957</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16696.88930</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.887236</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.055809</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.011680</td>\n",
       "      <td>0.012574</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>0.020086</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.023427</td>\n",
       "      <td>0.022772</td>\n",
       "      <td>0.021615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34464</th>\n",
       "      <td>120526</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7</td>\n",
       "      <td>197.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>91.457143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33975.48000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.834819</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109475</th>\n",
       "      <td>32363</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46261.96145</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26449</th>\n",
       "      <td>100534</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>20042.95930</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.523810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>213334</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20042.95930</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1853.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.894737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76726</th>\n",
       "      <td>87237</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32773.98348</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.834819</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.017509</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>63855</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15057.31500</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.878359</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.071586</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>0.008085</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.012683</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>0.019751</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127718</th>\n",
       "      <td>103394</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>338.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37117.18302</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.885211</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.047380</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>0.007991</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.015477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107091</th>\n",
       "      <td>267662</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37032.75842</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.834819</td>\n",
       "      <td>0.873557</td>\n",
       "      <td>0.873409</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.074853</td>\n",
       "      <td>0.065468</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.008724</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.009880</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018708</td>\n",
       "      <td>0.019172</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>0.017468</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>0.018387</td>\n",
       "      <td>0.013386</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>0.015477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age_indicator  month_id  spent_time_total  failed_hw  \\\n",
       "83245   151631           20.0         9              38.0        0.0   \n",
       "122826  183957           20.0        10              38.0        0.0   \n",
       "34464   120526           32.0         7             197.0        0.0   \n",
       "109475   32363           20.0        12               8.0        0.0   \n",
       "26449   100534           10.0         6              38.0        0.0   \n",
       "...        ...            ...       ...               ...        ...   \n",
       "9704    213334           38.0         3              38.0        0.0   \n",
       "76726    87237           30.0         5              38.0        0.0   \n",
       "9256     63855           17.0         3              38.0        0.0   \n",
       "127718  103394           10.0         6             338.0        0.0   \n",
       "107091  267662           25.0        10              91.0        0.0   \n",
       "\n",
       "        reworked_hw  avg_hw_mark  test_with_good_mark  webinars  \\\n",
       "83245           0.0          0.0                  0.0       0.0   \n",
       "122826          0.0          0.0                  0.0       0.0   \n",
       "34464           0.0        100.0                  0.0       3.0   \n",
       "109475          0.0          0.0                  0.0       1.0   \n",
       "26449           0.0          0.0                  0.0       0.0   \n",
       "...             ...          ...                  ...       ...   \n",
       "9704            0.0          0.0                  0.0       0.0   \n",
       "76726           0.0          0.0                  0.0       0.0   \n",
       "9256            0.0          0.0                  0.0       0.0   \n",
       "127718          0.0          0.0                  4.0       0.0   \n",
       "107091         25.0        100.0                  0.0       8.0   \n",
       "\n",
       "        avg_quiz_result  notes  hw_leader  activity  bought_d1  bought_d2  \\\n",
       "83245          0.000000    0.0        0.0       9.0          0          0   \n",
       "122826         0.000000    0.0        0.0       9.0          0          0   \n",
       "34464         91.457143    0.0        0.0      40.0          0          0   \n",
       "109475         0.000000    0.0        0.0       4.0          0          0   \n",
       "26449          0.000000    0.0        0.0       9.0          0          0   \n",
       "...                 ...    ...        ...       ...        ...        ...   \n",
       "9704           0.000000    0.0        0.0       9.0          0          0   \n",
       "76726          0.000000    0.0        0.0       9.0          0          0   \n",
       "9256           0.000000    0.0        0.0       9.0          0          0   \n",
       "127718         0.000000  378.0        0.0      14.0          0          0   \n",
       "107091         0.000000    0.0        0.0      25.0          0          0   \n",
       "\n",
       "        bought_d3  bought_d4  bought_d5  bought_avg_duration  payment_type  \\\n",
       "83245           0          0          0                  0.0             1   \n",
       "122826          0          0          0                  0.0             1   \n",
       "34464           0          0          0                  0.0             1   \n",
       "109475          0          0          0                  0.0             2   \n",
       "26449           0          0          0                  0.0             1   \n",
       "...           ...        ...        ...                  ...           ...   \n",
       "9704            0          0          0                  0.0             2   \n",
       "76726           0          0          0                  0.0             1   \n",
       "9256            0          0          0                  0.0             1   \n",
       "127718          0          0          0                  0.0             1   \n",
       "107091          0          0          0                  0.0             2   \n",
       "\n",
       "        promo        price  auto_payment  gender  speed_recall  \\\n",
       "83245       1  35385.97720             0     0.0           0.0   \n",
       "122826      0  16696.88930             1     0.0           0.0   \n",
       "34464       0  33975.48000             0     2.0           0.0   \n",
       "109475      1  46261.96145             1     1.0           0.0   \n",
       "26449       0  20042.95930             0     2.0           0.0   \n",
       "...       ...          ...           ...     ...           ...   \n",
       "9704        0  20042.95930             0     2.0           4.0   \n",
       "76726       0  32773.98348             0     1.0           0.0   \n",
       "9256        0  15057.31500             0     2.0           0.0   \n",
       "127718      0  37117.18302             1     1.0           0.0   \n",
       "107091      1  37032.75842             0     2.0           0.0   \n",
       "\n",
       "        m_avg_duration  m_total_calls  p_total_calls  p_was_conversations  \\\n",
       "83245              0.0            0.0            0.0                  0.0   \n",
       "122826             3.5            9.0            0.0                  0.0   \n",
       "34464              2.0            2.0            0.0                  0.0   \n",
       "109475             0.0            0.0            0.0                  0.0   \n",
       "26449             88.0            2.0            0.0                  0.0   \n",
       "...                ...            ...            ...                  ...   \n",
       "9704            1853.0            1.0            1.0                  1.0   \n",
       "76726              0.0            0.0            0.0                  0.0   \n",
       "9256               0.0            0.0            0.0                  0.0   \n",
       "127718          1091.0            2.0            0.0                  0.0   \n",
       "107091             0.0            0.0            0.0                  0.0   \n",
       "\n",
       "        p_total_duration  support_feedback_avg  feedback_avg_d1  \\\n",
       "83245                0.0                   5.0         0.000000   \n",
       "122826               0.0                   0.0         4.400000   \n",
       "34464                0.0                   0.0         0.000000   \n",
       "109475               0.0                   0.0         0.000000   \n",
       "26449                0.0                   5.0         4.523810   \n",
       "...                  ...                   ...              ...   \n",
       "9704               174.0                   5.0         4.894737   \n",
       "76726                0.0                   5.0         0.000000   \n",
       "9256                 0.0                   0.0         0.000000   \n",
       "127718               0.0                   0.0         0.000000   \n",
       "107091               0.0                   5.0         0.000000   \n",
       "\n",
       "        feedback_avg_d2  feedback_avg_d3  feedback_avg_d4  feedback_avg_d5  \\\n",
       "83245               0.0              0.0              0.0              0.0   \n",
       "122826              0.0              0.0              0.0              0.0   \n",
       "34464               0.0              0.0              5.0              5.0   \n",
       "109475              0.0              0.0              0.0              0.0   \n",
       "26449               0.0              0.0              0.0              0.0   \n",
       "...                 ...              ...              ...              ...   \n",
       "9704                0.0              0.0              0.0              5.0   \n",
       "76726               0.0              0.0              5.0              0.0   \n",
       "9256                0.0              0.0              0.0              0.0   \n",
       "127718              0.0              0.0              0.0              0.0   \n",
       "107091              0.0              4.9              0.0              0.0   \n",
       "\n",
       "        day_id  day_of_week_id  carts_created_at_month  carts_created_at_day  \\\n",
       "83245       30               3                      11                    12   \n",
       "122826      31               6                       7                     5   \n",
       "34464       31               5                       5                    20   \n",
       "109475      31               3                       9                     8   \n",
       "26449       30               2                      11                    12   \n",
       "...        ...             ...                     ...                   ...   \n",
       "9704        31               2                       7                     6   \n",
       "76726       31               0                       3                    13   \n",
       "9256        31               2                      10                    28   \n",
       "127718      30               2                       4                    19   \n",
       "107091      31               6                       2                     8   \n",
       "\n",
       "        carts_created_at_day_of_week  program_id_0  student_id_0     ABC_0  \\\n",
       "83245                              3           871       6894793  0.878359   \n",
       "122826                             0          1126       5865616  0.887236   \n",
       "34464                              3           562       6662811  0.834819   \n",
       "109475                             1          1233       6798177  0.878359   \n",
       "26449                              3           211       6703712  0.878359   \n",
       "...                              ...           ...           ...       ...   \n",
       "9704                               0           176       6684923  0.878359   \n",
       "76726                              5           549       6988242  0.834819   \n",
       "9256                               2           518       6857933  0.878359   \n",
       "127718                             0          1635       7162362  0.885211   \n",
       "107091                             0           490       7024377  0.834819   \n",
       "\n",
       "          city_0  country_0  program_id_1  student_id_1     ABC_1    city_1  \\\n",
       "83245   0.873557   0.873409           871       6894793  0.071586  0.065468   \n",
       "122826  0.873557   0.873409          1126       5865616  0.055809  0.065468   \n",
       "34464   0.873557   0.873409           562       6662811  0.074853  0.065468   \n",
       "109475  0.873557   0.873409          1233       6798177  0.071586  0.065468   \n",
       "26449   0.873557   0.873409           211       6703712  0.071586  0.065468   \n",
       "...          ...        ...           ...           ...       ...       ...   \n",
       "9704    0.873557   0.873409           176       6684923  0.071586  0.065468   \n",
       "76726   0.873557   0.873409           549       6988242  0.074853  0.065468   \n",
       "9256    0.873557   0.873409           518       6857933  0.071586  0.065468   \n",
       "127718  0.873557   0.873409          1635       7162362  0.047380  0.065468   \n",
       "107091  0.873557   0.873409           490       7024377  0.074853  0.065468   \n",
       "\n",
       "        program_id_2  student_id_2  communication_type_2    city_2  country_2  \\\n",
       "83245            871       6894793              0.006642  0.008724   0.008692   \n",
       "122826          1126       5865616              0.009859  0.008724   0.008692   \n",
       "34464            562       6662811              0.009859  0.008724   0.008692   \n",
       "109475          1233       6798177              0.006642  0.008724   0.008692   \n",
       "26449            211       6703712              0.009859  0.008724   0.008692   \n",
       "...              ...           ...                   ...       ...        ...   \n",
       "9704             176       6684923              0.009859  0.008724   0.008692   \n",
       "76726            549       6988242              0.006642  0.008724   0.008692   \n",
       "9256             518       6857933              0.009859  0.008724   0.008692   \n",
       "127718          1635       7162362              0.009859  0.008724   0.008692   \n",
       "107091           490       7024377              0.009859  0.008724   0.008692   \n",
       "\n",
       "            os_2  browser_2  program_id_3  student_id_3  communication_type_3  \\\n",
       "83245   0.008085   0.008085           871       6894793              0.017509   \n",
       "122826  0.011680   0.012574          1126       5865616              0.015146   \n",
       "34464   0.008085   0.008085           562       6662811              0.015146   \n",
       "109475  0.008085   0.008085          1233       6798177              0.017509   \n",
       "26449   0.008085   0.008085           211       6703712              0.015146   \n",
       "...          ...        ...           ...           ...                   ...   \n",
       "9704    0.008085   0.008085           176       6684923              0.015146   \n",
       "76726   0.008085   0.008085           549       6988242              0.017509   \n",
       "9256    0.008085   0.008085           518       6857933              0.015146   \n",
       "127718  0.009880   0.008880          1635       7162362              0.015146   \n",
       "107091  0.009880   0.008880           490       7024377              0.015146   \n",
       "\n",
       "          city_3  country_3  program_id_4  student_id_4    city_4  country_4  \\\n",
       "83245   0.015202   0.015133           871       6894793  0.018716   0.018708   \n",
       "122826  0.015202   0.015133          1126       5865616  0.018716   0.018708   \n",
       "34464   0.015202   0.015133           562       6662811  0.018716   0.018708   \n",
       "109475  0.015202   0.015133          1233       6798177  0.018716   0.018708   \n",
       "26449   0.015202   0.015133           211       6703712  0.018716   0.018708   \n",
       "...          ...        ...           ...           ...       ...        ...   \n",
       "9704    0.015202   0.015133           176       6684923  0.018716   0.018708   \n",
       "76726   0.015202   0.015133           549       6988242  0.018716   0.018708   \n",
       "9256    0.015202   0.015133           518       6857933  0.018716   0.018708   \n",
       "127718  0.015202   0.015133          1635       7162362  0.018716   0.018708   \n",
       "107091  0.015202   0.015133           490       7024377  0.018716   0.018708   \n",
       "\n",
       "        browser_4  program_id_5  student_id_5     ABC_5    city_5  country_5  \\\n",
       "83245    0.012683           871       6894793  0.019751  0.018333   0.018387   \n",
       "122826   0.025598          1126       5865616  0.020086  0.018333   0.018387   \n",
       "34464    0.012683           562       6662811  0.017468  0.018333   0.018387   \n",
       "109475   0.012683          1233       6798177  0.019751  0.018333   0.018387   \n",
       "26449    0.012683           211       6703712  0.019751  0.018333   0.018387   \n",
       "...           ...           ...           ...       ...       ...        ...   \n",
       "9704     0.012683           176       6684923  0.019751  0.018333   0.018387   \n",
       "76726    0.012683           549       6988242  0.017468  0.018333   0.018387   \n",
       "9256     0.012683           518       6857933  0.019751  0.018333   0.018387   \n",
       "127718   0.019172          1635       7162362  0.007991  0.018333   0.018387   \n",
       "107091   0.019172           490       7024377  0.017468  0.018333   0.018387   \n",
       "\n",
       "            os_5  browser_5  platform_5  \n",
       "83245   0.018393   0.018393    0.018390  \n",
       "122826  0.023427   0.022772    0.021615  \n",
       "34464   0.018393   0.018393    0.018390  \n",
       "109475  0.018393   0.018393    0.018390  \n",
       "26449   0.018393   0.018393    0.018390  \n",
       "...          ...        ...         ...  \n",
       "9704    0.018393   0.018393    0.018390  \n",
       "76726   0.018393   0.018393    0.018390  \n",
       "9256    0.018393   0.018393    0.018390  \n",
       "127718  0.013386   0.012513    0.015477  \n",
       "107091  0.013386   0.012513    0.015477  \n",
       "\n",
       "[160000 rows x 75 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a9a655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем модель\n",
    "model = RandomForestClassifier(n_jobs=-1, max_depth=20, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc36302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t18\n",
      "Tentative: \t0\n",
      "Rejected: \t57\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t18\n",
      "Tentative: \t0\n",
      "Rejected: \t57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x182979F4040),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x182979F4040,\n",
       "         verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x182979F4040),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x182979F4040,\n",
       "         verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=90, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x182979F4040)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=90, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x182979F4040)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x182979F4040),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x182979F4040,\n",
       "         verbose=2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector = BorutaPy(model, n_estimators=90, verbose=2)\n",
    "feat_selector.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f94668",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = []\n",
    "un_selected_features = []\n",
    "for importance, col in list(zip(feat_selector.support_, X_train.columns)):\n",
    "    if importance == True:\n",
    "        selected_features.append(col)\n",
    "    else:\n",
    "        un_selected_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdf09518",
   "metadata": {},
   "outputs": [],
   "source": [
    "un_selected_features = list(set(un_selected_features) - set([f'program_id_{i}'for i in range(5)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f020434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2578391909.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2578391909.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2578391909.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test.drop(un_selected_features, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(un_selected_features, 1, inplace=True)\n",
    "X_val.drop(un_selected_features, 1, inplace=True)\n",
    "X_test.drop(un_selected_features, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96926a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_indicator</th>\n",
       "      <th>month_id</th>\n",
       "      <th>price</th>\n",
       "      <th>carts_created_at_month</th>\n",
       "      <th>carts_created_at_day</th>\n",
       "      <th>program_id_0</th>\n",
       "      <th>student_id_0</th>\n",
       "      <th>program_id_1</th>\n",
       "      <th>student_id_1</th>\n",
       "      <th>program_id_2</th>\n",
       "      <th>student_id_2</th>\n",
       "      <th>program_id_3</th>\n",
       "      <th>student_id_3</th>\n",
       "      <th>program_id_4</th>\n",
       "      <th>student_id_4</th>\n",
       "      <th>program_id_5</th>\n",
       "      <th>student_id_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83245</th>\n",
       "      <td>151631</td>\n",
       "      <td>20.0</td>\n",
       "      <td>9</td>\n",
       "      <td>35385.97720</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "      <td>871</td>\n",
       "      <td>6894793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122826</th>\n",
       "      <td>183957</td>\n",
       "      <td>20.0</td>\n",
       "      <td>10</td>\n",
       "      <td>16696.88930</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "      <td>1126</td>\n",
       "      <td>5865616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34464</th>\n",
       "      <td>120526</td>\n",
       "      <td>32.0</td>\n",
       "      <td>7</td>\n",
       "      <td>33975.48000</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "      <td>562</td>\n",
       "      <td>6662811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109475</th>\n",
       "      <td>32363</td>\n",
       "      <td>20.0</td>\n",
       "      <td>12</td>\n",
       "      <td>46261.96145</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "      <td>1233</td>\n",
       "      <td>6798177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26449</th>\n",
       "      <td>100534</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>20042.95930</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "      <td>211</td>\n",
       "      <td>6703712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9704</th>\n",
       "      <td>213334</td>\n",
       "      <td>38.0</td>\n",
       "      <td>3</td>\n",
       "      <td>20042.95930</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "      <td>176</td>\n",
       "      <td>6684923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76726</th>\n",
       "      <td>87237</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5</td>\n",
       "      <td>32773.98348</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "      <td>549</td>\n",
       "      <td>6988242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9256</th>\n",
       "      <td>63855</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3</td>\n",
       "      <td>15057.31500</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "      <td>518</td>\n",
       "      <td>6857933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127718</th>\n",
       "      <td>103394</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "      <td>37117.18302</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "      <td>1635</td>\n",
       "      <td>7162362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107091</th>\n",
       "      <td>267662</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10</td>\n",
       "      <td>37032.75842</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "      <td>490</td>\n",
       "      <td>7024377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age_indicator  month_id        price  carts_created_at_month  \\\n",
       "83245   151631           20.0         9  35385.97720                      11   \n",
       "122826  183957           20.0        10  16696.88930                       7   \n",
       "34464   120526           32.0         7  33975.48000                       5   \n",
       "109475   32363           20.0        12  46261.96145                       9   \n",
       "26449   100534           10.0         6  20042.95930                      11   \n",
       "...        ...            ...       ...          ...                     ...   \n",
       "9704    213334           38.0         3  20042.95930                       7   \n",
       "76726    87237           30.0         5  32773.98348                       3   \n",
       "9256     63855           17.0         3  15057.31500                      10   \n",
       "127718  103394           10.0         6  37117.18302                       4   \n",
       "107091  267662           25.0        10  37032.75842                       2   \n",
       "\n",
       "        carts_created_at_day  program_id_0  student_id_0  program_id_1  \\\n",
       "83245                     12           871       6894793           871   \n",
       "122826                     5          1126       5865616          1126   \n",
       "34464                     20           562       6662811           562   \n",
       "109475                     8          1233       6798177          1233   \n",
       "26449                     12           211       6703712           211   \n",
       "...                      ...           ...           ...           ...   \n",
       "9704                       6           176       6684923           176   \n",
       "76726                     13           549       6988242           549   \n",
       "9256                      28           518       6857933           518   \n",
       "127718                    19          1635       7162362          1635   \n",
       "107091                     8           490       7024377           490   \n",
       "\n",
       "        student_id_1  program_id_2  student_id_2  program_id_3  student_id_3  \\\n",
       "83245        6894793           871       6894793           871       6894793   \n",
       "122826       5865616          1126       5865616          1126       5865616   \n",
       "34464        6662811           562       6662811           562       6662811   \n",
       "109475       6798177          1233       6798177          1233       6798177   \n",
       "26449        6703712           211       6703712           211       6703712   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "9704         6684923           176       6684923           176       6684923   \n",
       "76726        6988242           549       6988242           549       6988242   \n",
       "9256         6857933           518       6857933           518       6857933   \n",
       "127718       7162362          1635       7162362          1635       7162362   \n",
       "107091       7024377           490       7024377           490       7024377   \n",
       "\n",
       "        program_id_4  student_id_4  program_id_5  student_id_5  \n",
       "83245            871       6894793           871       6894793  \n",
       "122826          1126       5865616          1126       5865616  \n",
       "34464            562       6662811           562       6662811  \n",
       "109475          1233       6798177          1233       6798177  \n",
       "26449            211       6703712           211       6703712  \n",
       "...              ...           ...           ...           ...  \n",
       "9704             176       6684923           176       6684923  \n",
       "76726            549       6988242           549       6988242  \n",
       "9256             518       6857933           518       6857933  \n",
       "127718          1635       7162362          1635       7162362  \n",
       "107091           490       7024377           490       7024377  \n",
       "\n",
       "[160000 rows x 18 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039753c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "43defbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=11, n_estimators=180, tree_method='gpu_hist', n_jobs=-1, reg_lambda = 1, reg_alpha=1,\\\n",
    "                     objective = 'multi:softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "23292123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_weights(y):\n",
    "    weights = [abs(np.log((len(Y_train)-i)/i)) for i in list(Y_train.value_counts())]\n",
    "    temp = np.zeros(len(y))\n",
    "    for i in range(6):\n",
    "        temp[y == i] = weights[i]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c41f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_weights(y):\n",
    "    weights = [1.9141753459017434,\n",
    " 2.628525162773276,\n",
    " 4.2,\n",
    " 3.9809940485731774,\n",
    " 4.172814623467616,\n",
    " 5.7]\n",
    "    temp = np.zeros(len(y))\n",
    "    for i in range(6):\n",
    "        temp[y == i] = weights[i]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c810ae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softmax&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" checked><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softmax&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective='multi:softmax',\n",
       "              predictor='auto', random_state=0, reg_alpha=1, ...)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, sample_weight=my_sample_weights(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4c1286a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98     34863\n",
      "         1.0       0.95      0.81      0.87      2740\n",
      "         2.0       0.94      0.71      0.81       383\n",
      "         3.0       0.94      0.82      0.88       599\n",
      "         4.0       0.95      0.85      0.90       727\n",
      "         5.0       0.91      0.81      0.86       688\n",
      "\n",
      "    accuracy                           0.97     40000\n",
      "   macro avg       0.94      0.83      0.88     40000\n",
      "weighted avg       0.97      0.97      0.97     40000\n",
      "\n",
      "Метрика: 0.921831432358588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAD4CAYAAAAn3bdmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA8kUlEQVR4nO3deXgUVdrw/+9JSDDAEBAjYBJCRJRlRgkoooAsYXUhiCggD6IywsurIoz+hEFHdB6dEZdxeZ9ncMAwRIZlkEVxAyKJikpCQrqzkUACcUjYRyQD6giE+/dHF5kGsnRIdzrV3p/rOle6T1X1ubug7pycOlVlRASllFL2EOTvAJRSSnlOk7ZSStmIJm2llLIRTdpKKWUjmrSVUspGmjRAG7abnmKM8XcISv0siYg3Dr665BzbHewNkbSVUqrhnDnt+bpB9kuB9otYKaVqoklbKaVspC5J24Y0aSulAosmbaWUspHT//Z3BD6lSVspFVi0p62UUjaiSVsppWxEk7ZSStmIJm2llLIRTdpKKWUjOntEKaVsRHvaSillIwGetBvs1qw//fQTY8eOZdSoUdx22228+eabF6yzdu1a+vTpQ0JCAgkJCbz77rv1bvfYsWM88MADDBs2jAceeIDy8vJzlufk5NCtWzc2bNhQ77bcXX311TgcjspSXl7OY489xrx58ygrK6usHzlypFfbrY/ExEQOHTpEbm5uZV3r1q3ZtGkTu3btYtOmTbRq1cp/AZ6nqnjP+s1vfoOI0KZNGz9EVrWoqChSUlLIz88nLy+PGTNmAPDSSy9RUFBAdnY2a9euJTw83M+R/kfTpk1JT0/H6XSSl5fHs88+C8CgQYPYvn07ubm5LFmyhODgYP8G6u7Mac+LHYmIr4uIiJw5c0ZOnDghIiInT56UsWPHisPhEHdr1qyR5557Ti5GWlqazJ49+4L6+fPny1/+8hcREfnLX/4iL730UuWy06dPy6RJk+TXv/61fPLJJ5X1uG7t6LUSFBQkBw4ckA4dOsi8efPk8ccf93ob3ij9+/eXuLg4yc3NraybP3++zJ49WwCZPXu2vPjii36Ps6Z4AYmKipINGzbIN998I23atPF7nGdLu3btJC4uTgBp0aKF7Ny5U7p27SpDhw6V4OBgAeTFF19sVPsYkObNmwsgTZo0kbS0NLnppptk79690rlzZwHkueeekwcffNArbXkl5+xOFo+L7/Of10uD9bSNMTRv3hyA06dPc/r06Trdt/rtt9/mrrvu4o477qiyl16dzZs3M3r0aABGjx7Np59+Wrls6dKlDB8+3Oe9sfj4eHbv3s3evXt92k59bdmyhaNHj55Tl5CQQFJSEgBJSUmV+7IxqCpegNdee40nn3wS1+/fxuPgwYM4HA4ATpw4QUFBAZGRkSQnJ1NRUQFAWloaUVFR/gzzAt9//z0AISEhhISEUFFRwcmTJykqKgIgOTmZu+66y58hnuv0vz0vNlRr0jbGdDHGzDbGvGmV2caYrhfTWEVFBQkJCdx8883cfPPNXHfddRess2nTJu644w5mzJjBgQMHAPjyyy/5xz/+werVq3n//ffJz88nIyPDoza//fZbLr/8cgAiIiL49ttvATh06BCffvopEyZMuJivUifjx49nxYoVle8feeQRsrOzSUxMbFTDDVVp27YtBw8eBFxJp23btn6OqGajRo1i37595OTk+DuUGsXExBAXF0d6evo59Q8++CCffPKJn6KqWlBQEA6Hg8OHD5OcnMy2bdto0qQJvXr1AmDs2LFER0f7OUo3AT48UmPSNsbMBlbierrDNqsYYIUxZk4N2001xmQaYzIXLlxYWR8cHMz777/P559/Tk5ODrt27Tpnu0GDBpGSksIHH3zAzTffzOzZswH46quv+Oqrrxg9ejR33nkne/bs4ZtvvgHg7rvvJiEhgaeffpqUlJTK8fAtW7ZUFVdl7/6FF17giSeeICjIt39shISEMGrUqMrx+QULFtCpUyd69OjBgQMHePXVV33avrc1tt6ru7CwMObOncszzzzj71Bq1Lx5c9asWcPMmTM5fvx4Zf3cuXM5ffo0y5Yt82N0Fzpz5gxxcXFERUXRu3dvunfvzvjx43nttddIT0/n+PHjlX8pNAoBnrRrmz0yBeguIqfcK40xfwLygRer2khEFgJns/UFR3nLli258cYb2bJlC1dffXVlfevWrStf33333bz88stnP4+pU6cyfvz4C9o6mwzT09NZt24dL754bkht2rTh8OHDXH755Rw+fJhLL70UgLy8PH7zm98A8N133/H555/TpEkThgwZUsPuqLuRI0eSlZXF4cOHASp/AixatIgPP/zQq+1526FDh2jXrh0HDx6kXbt258Tf2HTq1InY2Fiys7MB14m/rKwsevfuzaFDh/wcnUuTJk1Ys2YNy5YtY926dZX1kydP5vbbbyc+Pt6P0dWsvLyc1NRURowYwauvvsott9wCwNChQ885jv3OpsnYU7V1M88AV1RR395a5rGjR4/yr3/9C4B///vffP3111x55ZXnrOOeEFJSUujUqRMA/fr1Y82aNZVja4cOHaoc5qjN4MGDee+99wB47733Kg+KlJSUyjJ8+HDmzZvn9YQNMGHChHOGRtq1a1f5+s477yQvL8/rbXrT+vXrmTx5MuBKLO+//76fI6peXl4ebdu2JTY2ltjYWMrKyujZs2ejSdjgmvFSUFDAa6+9Vlk3fPhwnnzySUaNGsWPP/7ox+gudNlll1XOZrnkkksYOnQohYWFREREABAaGsrs2bN56623/BnmuX7mPe2ZwGZjTBFQatV1AK4CHqlLQ4cPH2bOnDlUVFQgIowYMYJBgwbxxhtv8Mtf/pL4+HiWLl1KSkoKwcHBhIeH88c//hFwJe3du3dX9rSbNWvGyy+/7NEJxKlTpzJz5kxWr17NFVdcweuvv16XsOulWbNmDB06lGnTplXWvfTSS/To0QMR4Ztvvjlnmb8tX76cgQMHctlll1FaWsq8efN48cUXWbVqFVOmTOEf//gH99xzj7/DrFRVvIsXL/Z3WNXq27cv9913Hzk5OZUnJOfOncubb75J06ZNSU5OBlwnI6dPn+7PUCu1b9+epKQkgoODCQoKYtWqVXz00Ue89NJL3H777QQFBbFgwQJSU1P9Hep/2DQZe8rUNkZpjAkCegORVtU+IENEPB3EaryDoNXQp7Er5R/ijaexZ77lec65/v/Y7mCv9YpIETkDpDVALEopVX8B3tPWy9iVUoFFk7ZSStmIJm2llLKRAE/aDXYZu1JKNQgvTfkzxlxijNlmjMk2xuQbY56z6mONMenGmGJjzN+NMaFWfVPrfbG1vKPbZ/3Wqt9pjBnuVj/Cqiuu6YJFd5q0lVKBxXv3HvkJGCwi1wE9gBHGmD7AfOA1EbkK+A7XRYhYP7+z6l+z1sMY0w0YD3QHRgB/NsYEG2OCgf8FRgLdgAnWujXSpK2UCixe6mlbN/08Yb0NsYoAg4HVVn0SMNp6nWC9x1oeb1zzhxOAlSLyk4iUAMW4plH3BopFZI+InMR1y5CE2r6eJm2lVGCpQ9J2v0+SVaa6f5TVI3YCh4FkYDdwTETOZvwy/nMNSyTWRYjW8nKgjXv9edtUV18jPRGplAosdTgRed59kqpaXgH0MMa0AtYBXeobXn1p0lZKBRYfzB4RkWPGmFTgJqCVMaaJ1ZuOwnWVONbPaKDMGNMECAe+das/y32b6uqrpcMjSqnA4qUTkcaYCKuHjTEmDBgKFACpwFhrtcnA2buorbfeYy1PsZ6EtR4Yb80uiQU647rNdQbQ2ZqNEorrZOX62r6e9rSVUoHFez3t9kCSNcsjCFglIh8aY3YAK40xzwMOINFaPxFYaowpBo7iSsKISL4xZhWwAzgNPHz23k3GmEeAjUAwsFhE8msLqtYbRnmB3jBKKeURr9wwau1/eZ5zxvzNdge79rSVUoElwK+I9HnSDrVhr7Vd7as0Kgf9HYBSjYkmbaWUshFN2kopZSO1X55ua5q0lVKBRXvaSillI5q0lVLKRjRpK6WUjWjSVkopG9GkrZRSNqKzR5RSyka0p62UUjaiSVsppWxEk7ZSStmIJm2llLKRAD8R6fcn1+wqKSErJ4cMh4OtGRn1/rxJ991H/q5d5O/axaT77gMgLCyM9z78kNyCApx5ebzwxz/W+jlXREWxOiWFz/Pz+Swvj1/PmHHBOmPuvZfN2dmk5OSw/quv6HbttfWOPzQ0lLdWruTroiI+SksjKiYGgB433ECyw0Gyw8GnTicjR4+ud1s1mTlzJnl5eeTm5rJ8+XKaNm3q0/YuRmJiIocOHSI3N7eybuzYseTl5VFRUUGvXr38GJ1ngoKCyMrK4oMPPvB3KFWy5T720tPYGy0R8WkJAamplJSUSLs2bWpcp6ryWWqqXBUTc07d5a1by+7du+Xy1q0lolUr2b17t0S0aiUtw8JkyMCBEgLSLCREtnzxhdw+YkS1n90O5Np27WRoXJy0A+nUooUU79wpt3TtKu2s5e1Abr/pJrmmVStpB3LviBGyPS3tnOU1letjYuSr1NQL6mdPny5JCxZIO5Bp48bJeytXSjuQ2LAwiQwOroztyKFDle/xcrniiitkz549cskllwggf//732Xy5Mleb6e+pX///hIXFye5ubmVdV26dJGrr75aUlNTpVevXn6PsbYya9YsWbZsmXzwwQd+j6Ux7GOv5J0XmovHxcf5zxfF7z3tqlx55ZV88MknpGVmkvLFF1xzzTUebTds+HA2Jyfz3XffcezYMTYnJzN8xAh+/PFHPv/sMwBOnTqFIyuLyKioGj/r8MGD5DocAHx/4gRFBQW0izz36faZW7dSfuwYANvT0mjv9pl3TZzIx+npJDscvPTWWwQFebarRyQksCopCYAPV6+mf3w8AD/++CMVFRUANL3kEnz9xKEmTZoQFhZGcHAwzZo1Y//+/T5t72Js2bKFo0ePnlNXWFjIrl27/BRR3URGRnLbbbfx9ttv+zuUatlyHwd4T9vvSVtE+HjTJtIyM5ny0EMA/HnhQmY9+ih9rr+e2U88wZt//rNHn3VFZCRlpaWV7/eVlXHFeYk2PDyc2+64g9TNmz2OMSomhl/FxZGVnl7tOhOmTCHlk08A6NylC6PGjWNU374MjYujoqKCuyZO9KitdpGR7Le+Q0VFBf8qL+fSNm0AiOvdm8/y8kjNzWX2//k/lUnc2/bv388rr7zC3r17OXDgAOXl5SQnJ/ukrZ+z119/nSeffJIzZ874O5TAEuBJ+6JPRBpjHhCRv1azbCowFVxPq6zpN8Ogfv3Yv38/ERERfJKczM7CQm66+WZWvPtu5Tpnx1Pvu/9+Hn3sMQA6XXUV6z/+mJMnT/JNSQl3jxlTa8zBwcEsXbGC/33zTUpKSjz6ns2aNydxzRqemTmTE8ePV7nOzQMHcu+UKST06wdAv/h4ru3Vi0+sMfpLwsL45+HDACxeu5bo2FhCQ0OJ7NCBZKs3//Ybb/D3JUtqjMWxbRsDf/lLOnfpwhtJSaR88gk//fSTR9+jLlq1akVCQgKxsbEcO3aMd999l4kTJ7Js2TKvt/Vzddttt3H48GGysrIYMGCAv8MJLGd805lpLOoze+Q5oMqkLSILgYUAocbU+Hf82T+7jxw5wvvr1jFg4ECOHTvGDXFxF6z7zpIlvGMltuTUVH59//384x//+M9n7dvHLQMHVr6PjIriC2tYBGDBwoUUFxXx/954w6Mv2KRJExLXrGHtsmV8vG5dlet0/dWvePXtt5k4ciTfWX9GGmN4NymJP8yde8H6D1q/XKJiYnhjyRLuGjTonOUH9+3jiuhoDuzbR3BwMC3Dwzn67bfnrFNUWMj3J07Q5Ze/JHv7do++S10MGTKEkpIS/vnPfwKwdu1abr75Zk3aXtS3b19GjRrFrbfeyiWXXELLli1ZunQpkyZN8ndo9mfPDrTHahweMcbkVFNygbb1bbxZs2a0aNGi8vWQYcPI2LaNb0pKuGvs2Mr1rvVwVsamjRsZMmwYrVq1olWrVgwZNoxNGzcC8Nx//zfh4eE8PnOmx/H9KTGRooIC/vLaa1Uuj4yOJnHtWh6dNIk9RUWV9V9u3sxtY8fSJiICgFatWxPVoYNHbW5cv557Jk8G4PaxY/kyJQWA6I4dCQ4OBiCqQweu6tKF0m++8fi71MXevXvp06cPYWFhAMTHx1NQUOCTtn6u5s6dS3R0NLGxsYwfP56UlBRN2N5ypg7Fjmo6SwkcAnoAMeeVjsD++s4euTo2VrKdTsl2OiU/L09+N3euhIB07thRNnzyiWQ7nbIjP1+e/d3vPJo9EgLy6wcekKKiIikqKpIp998vISAdIyNFRKRgxw5xOhzidDhk6pQpNc4eGdW3r4iI5GdnS67DIbkOh9w7cqQ8OW2aPDltmrQD+duiRfLd0aOVy50ZGZWzQKbec4/kOhySn50t2ZmZcuuNN3o0eySmaVNZv2qV7Ckqkqz0dOkdGyvtQB75r/+Swrw8yXU4JGf7drk/IaFyG3xQnn32WSkoKJDc3Fx55513JDQ01O8zGc4vy5cvl/3798vJkyeltLRUHnzwQRk9erSUlpbKv//9bzl48KBs2LDB73HWVgYMGNBoZ4809D72ygyL2YjHpeb8Fw2kAjuAfOAxq/5ZYB/gtMqtbtv8FigGdgLD3epHWHXFwBy3+lgg3ar/OxBa2/czNc1CMMYkAn8VkS+rWLZcRO6tdmNLbcMjjVEbfwdQR/o0dhUoRMTU+0OerEPOean69owx7YH2IpJljPkFsB0YDdwDnBCRV85bvxuwAugNXAF8ClxtLd4FDAXKgAxggojsMMasAtaKyEpjzFtAtogsqCnkGodHRGRKVQnbWlZrwlZKqQbnpeERETkgIlnW6+NAARBZwyYJwEoR+UlESnD1nntbpVhE9ojISWAlkGCMMcBgYLW1fRKuXwo18vuUP6WU8qo6JG1jzFRjTKZbmVrVRxpjOgJxuIYyAB6xzu8tNsa0tuoigVK3zcqsuurq2wDHROT0efU10qStlAospz0vIrJQRK53KwvP/zhjTAtgDTBTRP4FLAA64TrfdwB41fdf6j/0hlFKqcDixVkhxpgQXAl7mYisBRCRQ27LFwEfWm/34Tp5eVaUVUc19d8CrYwxTazetvv61dKetlIqsHhpTNsac04ECkTkT2717d1WuxPIs16vB8YbY5oaY2KBzsA2XCceOxtjYo0xocB4YL24ZoGkAmfnN08G3q/t62lPWykVWLzX0+4LTAJyjTFOq24uMMEY0wPXNMVvgGkAIpJvzQbZgWsA5mERqQAwxjwCbMR1kfhiEcm3Pm82sNIY8zzgwPVLokY1TvnzBp3y53s65U8FCq9M+Ztah5yz0AvtNTDtaSulAkuAX8auSVspFVjsenm6hzRpK6UCiyZtpZSyEU3aSillI5q0lVLKRjRp188pXzfgA3abQhfs7wAuQmA/W0T5k9Rh9ojt5vuhPW2lVICpyyM37djh0aStlAooosMjSillH4H+cHtN2kqpgKI9baWUshHtaSullI1U6L1HlFLKPnR4RCmlbESHR5RSyka0p62UUjaiPW2llLIRPRGplFI2oj1tpZSykUAf0w7ydwCemjFjBrm5ueTl5fHYY48BsHLlShwOBw6Hg5KSEhwOh5+jrF54eDjvvvsuBQUF7Nixgz59+ni9jaioKD5NSSEnP5/svDwenTHjgnUef+IJMh0OMh0OnLm5/HT6NK1bt65Xu6GhoSxfuZLCoiK+TksjJiYGgCFDhpCemYkjJ4f0zEwGDRpUr3Zq0rRpU9LT03E6neTl5fHss8/6rC1vSUxM5NChQ+Tm5vo7FI/YZR+fOeN5sSUR8WnB9Zj5epXu3btLbm6uhIWFSXBwsCQnJ0unTp3OWeeVV16R3/3ud/Vuy1dlyZIlMmXKFAEkJCREwsPDvfbZwVaJbNdOro+Lk2CQ8BYtZOfOnfLLrl0rl59fEm6/XVI2b652+fnlypgY+Sw19YL6h6dPl7cWLJBgkAnjxsnfV66UYJBePXpIVPv2EgxybffuUlZWVrmNL/Zx8+bNBZAmTZpIWlqa3HjjjX7/d6+p9O/fX+Li4iQ3N9fvsTSWfeyNnFMWh3hafJ3/fFFs0dPu2rUr6enp/Pjjj1RUVPD5558zZsyYc9a55557WLFihZ8irFnLli255ZZbSExMBODUqVOUl5d7vZ2DBw9W/rVx4sQJCgsKiIyMrHb9cRMmsNJtn907cSJb09PJdDj481tvERTk2X+PUQkJLE1KAmDN6tUMjo8HwOl0cuDAAQDy8/MJCwsjNDT0or6bJ77//nsAQkJCCAkJOdtpaLS2bNnC0aNH/R1GndhhH8sZz0tNjDHRxphUY8wOY0y+MeYxq/5SY0yyMabI+tnaqjfGmDeNMcXGmBxjTE+3z5psrV9kjJnsVt/LGJNrbfOmMabWW3zXelQaY7oYY+KNMS3Oqx9R27bekpeXR//+/bn00ksJCwvj1ltvJTo6unJ5//79OXToEMXFxQ0VUp3ExsZy5MgR/vrXv5KVlcWiRYto1qyZT9uMiYmhR1wc6enpVS4PCwtj+IgRrF2zBoAuXbpwz7hx9O/bl+vj4qioqODeiRM9auuKyEhKS0sBqKiooLy8nDZt2pyzzpi77sKRlcXJkyfr8a1qFhQUhMPh4PDhwyQnJ7Nt2zaftfVzZYd9XHHa81KL08DjItIN6AM8bIzpBswBNotIZ2Cz9R5gJNDZKlOBBeBK8sA84EagNzDvbKK31nnIbbta82qNSdsYMwN4H3gUyDPGJLgt/kMN2001xmQaYzJrC8AThYWFzJ8/n02bNrFhwwacTicVFf959smECRMabS8boEmTJvTs2ZMFCxbQs2dPvv/+e+bMmVP7hhepefPmrFqzht/MnMnx48erXOf2O+7g66++4rvvvgNgcHw8PXv1Ii0jg0yHg8Hx8Vx55ZUArF67lkyHgw8+/phe119fOSY++f77PYqnW7du/HH+fKZPm+aV71edM2fOEBcXR1RUFL1796Z79+4+be/nyA772Ftj2iJyQESyrNfHgQIgEkgAkqzVkoDR1usE4B1xSQNaGWPaA8OBZBE5KiLfAcnACGtZSxFJE9efLO+4fVa1aps98hDQS0ROGGM6AquNMR1F5A1qeFKPiCwEFgIYY7zy99PixYtZvHgxAC+88AJlZWUABAcHM2bMGHr16uWNZnyirKyMsrKyyl7J6tWrfZa0mzRpwrtr1rBi2TLeW7eu2vXGjR9/ztCIMYalSUk8NXfuBeuOtYaiYmJiWLxkCfHnnVDcv28f0dHR7Nu3j+DgYMLDw/n2228BiIyMZPW6dTxw333s2bPHG1+xVuXl5aSmpjJixAjy8/MbpM2fm8a8j+tygtEYMxVXr/ishVb+On+9jkAckA60FZED1qKDQFvrdSRQ6rZZmVVXU31ZFfU1qm14JEhETgCIyDfAQGCkMeZPNPDj1SIiIgCIjo5mzJgxLF++HHDNUCgsLGTfvn0NGU6dHDp0iNLSUq6++moA4uPj2bFjh0/aWpSYSEFBAa+/9lq167Rs2ZJbBgxg/fvvV9albN7MmLFjK/dz69at6dChg0dtfrB+PZMmu4bp7ho7ltSUFMA1Y2b9Rx8xd84cvv7664v9Sh657LLLCA8PB+CSSy5h6NChFBYW+rTNnxu77OO6jGmLyEIRud6tVJWwWwBrgJki8q9z2nL1kBt0YL+2nvYhY0wPEXECWD3u24HFwK98HZy7NWvW0KZNG06dOsXDDz9ceSJv/PjxjXpo5KxHH32UZcuWERoayp49e3jggQe83kbfvn2ZdN995OTkkGmdkPzd3LlEW8l34V/+AsDoO+8kedMmfvjhh8ptCwoKeObpp/lk0yaCgoI4deoUMx5+mL1799ba7uLERJKWLqWwqIjvjh7l3vHjAXj4kUe46qqrePqZZ3j6mWcAGDlsGEeOHPHq9wZo3749SUlJBAcHExQUxKpVq/joo4+83o43LV++nIEDB3LZZZdRWlrKvHnzKv+abIzsso+9OU/bGBOCK2EvE5G1VvUhY0x7ETlgDXEctur3AdFum0dZdftwdXjd6z+z6qOqWL/mmGo6+2uMiQJOi8gFDyg3xvQVka9qbcBLwyOqenZ8OKk+jV1VRUTq/Rd8YUfPc06Xb6pvz5rJkQQcFZGZbvUvA9+KyIvGmDnApSLypDHmNuAR4FZcJx3fFJHe1onI7cDZ2SRZuIadjxpjtgEzcA27fAz8PxH5uKaYa+xpi0hZDctqTdhKKdXQvHjRTF9gEpBrjHFadXOBF4FVxpgpwD+Ae6xlH+NK2MXAD8ADAFZy/m8gw1rv9yJydq7n/wWWAGHAJ1apUY09bW/QnrbvaU9bBQpv9LTzozzPOd3L6t9eQ9N7jyilAoptL0/3kCZtpVRACfQbRmnSVkoFFO1pK6WUjehDEJRSykZ0eEQppWxEh0eUUspGtKetlFI2oj1tpZSyEU3aSillI2d09ohSStmH9rRVo2fH+3iE+DuAi3DK3wEojzTCx1Z6lSZtpVRACfCOtiZtpVRg0aStlFI2oklbKaVsRJO2UkrZiCZtpZSykQCfPKJJWykVWDRpK6WUjejwiFJK2YgdLzarC03aSqmAosMjSillI4E+PBLk7wCUUsqbpA6lNsaYxcaYw8aYPLe6Z40x+4wxTqvc6rbst8aYYmPMTmPMcLf6EVZdsTFmjlt9rDEm3ar/uzEmtLaYNGkrpQLKmToUDywBRlRR/5qI9LDKxwDGmG7AeKC7tc2fjTHBxphg4H+BkUA3YIK1LsB867OuAr4DptQWkG2S9owZM8jNzSUvL4/HHnsMgOuuu46tW7ficDjIyMjghhtu8HOUVbv66qtxOByVpby8vPI7NFbDhw+nsLCQoqIiZs+e7dO2goKC2JaVxboPPrhgWYcOHdjw6adsz84mOTWVyMjIerfXunVrPt60ifxdu/h40yZatWoFwIR772V7djZZOTl8/tVXXHvttfVuqyZRUVGkpKSQn59PXl4eM2bM8Gl79WWXeL3Z0xaRL4CjHjadAKwUkZ9EpAQoBnpbpVhE9ojISWAlkGCMMcBgYLW1fRIw2pOgfFo83Hc1lu7du0tubq6EhYVJcHCwJCcnS6dOnWTjxo0yYsQIAWTkyJGSmppa77Z8XYKCguTAgQPSoUMHv8dSU4zFxcUSGxsrISEh4nQ6pWvXrl5tI8StPDFrlqxYtkw+/OCDc+pDQFavWiUP3nefhIAMHTRI/vbOOxesU12JHzBAkv761wvqX5k/X+bOni0hIHNnz5aXX3xRQkD633STRLRqJSEgt48YIelpaeds5+393K5dO4mLixNAWrRoITt37vT6frZbvN7IOUtBPC3AVCDTrUytIod1BPLc3j8LfAPkAIuB1lb9/wD/5bZeIjDWKm+71U+y1r0MVzI/Wx/t3k51xRY97a5du5Kens6PP/5IRUUFn3/+OWPGjEFEaNmyJQDh4eHs37/fz5HWLj4+nt27d7N3715/h1Kt3r17U1xcTElJCadOnWLlypUkJCT4pK3IyEhG3nYbi99+u8rlXbt1IzUlBYDPUlO5wy2O3zzxBF9v28b27GyeefZZj9u8IyGBpUlJACxNSmLU6NEApG3dyrFjxwBIT0sjMiqq7l+oDg4ePIjD4QDgxIkTFBQUeOUvCV+xS7x1/C2xUESudysLPWhiAdAJ6AEcAF71+peoQa1J2xjT2xhzg/W6mzHmN+4D7w0hLy+P/v37c+mllxIWFsatt95KdHQ0M2fO5OWXX2bv3r288sor/Pa3v23IsC7K+PHjWbFihb/DqFFkZCSlpaWV78vKynx2cL76+uv89sknOVPN40ZysrMZPWYMAKPvvJOWLVty6aWXMmToUK7q3Jmbe/fm+h49iOvVi379+3vU5uVt23Lw4EHAlYgub9v2gnUemDKFjZ98cpHfqu5iYmKIi4sjPT29wdqsj8Ycb12S9kV9vsghEakQkTPAIlzDHwD7cPWWz4qy6qqr/xZoZYxpcl59jWpM2saYecCbwAJjzB9xdembA3OMMU/VsN1UY0ymMSaztgA8UVhYyPz589m0aRMbNmzA6XRSUVHB9OnTmTVrFh06dGDWrFkkJiZ6ozmfCQkJYdSoUbz77rv+DqVRuPW22zh8+DCOrKxq15n9xBPcMmAA27Ky6D9gAGVlZVRUVDBk2DCGDBtGhsPBtqwsrunShas6dwbgy7Q0MhwO3nr7bW4fNYoMh4MMh4Ohw4ZV2Yac96iTAQMH8sCUKcz18Vj+Wc2bN2fNmjXMnDmT48ePN0ib9dHY4/XyicgLGGPau729Ezg7s2Q9MN4Y09QYEwt0BrYBGUBna6ZIKK6TlevF9R8vFdfwCcBk4P1aA6hlPDoXCAaaAf8CWlr1YUBOQ41pn19eeOEFmT59uhw7duyc+vLycr+P+9VURo0aJRs3bvR7HLWVPn36yIYNGyrfz5kzR+bMmePVNkJA5v/hD1JaWiolJSVy4MAB+f7772XZ0qXVjlG3at5cSktLJQTkT6+8ItOnTr2oMe2dhYUS3a6dhIBEt2snOwsLK5f1/NWvpLi4WLp17nzBdr7Y102aNJENGzbIrFmz/P7v3hji9caY9mIQT4sH+WsFriGQU0AZrtkdS3Hlxhxcibq92/pPAbuBncBIt/pbgV3Wsqfc6q/EldiLgXeBprXGVEvAjqpeW++dDZm0IyIiBJDo6GgpKCiQ8PBw2bFjhwwYMEAAGTx4sGRmZvr9P3VNZcWKFXL//ff7PY7aSnBwsOzevVs6duxYeSKyW7duXm2jqgRb1YnIdm3aSKgxEgLyx+efl+efe05CQEYOHSrpaWnSqnlzCQGJueIKuSIiwrMTkS+9dM6JyFfmz5cQkCujo6WoqEj633RTlb8EfLGvk5KS5LXXXvP7v3ljidcbSXsRiKfFG+01dKkt4aYDzazXQW714UBWQybtL774QvLz88XpdMrgwYMFkL59+0pmZqY4nU5JS0uTnj17+v0/dXWlWbNm8s9//lNatmzp91g8KSNHjpSdO3dKcXGxzJ071+ufX1PSfv655+TOO+6QEJBxd90lu3btkl07d0riokXSPDS0cptZM2ZIbk6O5ObkyNavv5ZrrrzSo6Td9tJLZfOnn8quXbvk0+Rkubx1awkBSVy0SI4ePSpOh0OcDodkZmT4NGn37dtXRESys7PF4XCIw+GQkSNH+v3f3p/xeiOp/QXE0+LvBHwxxViJtUrGmKYi8lMV9Zfh+pMgt9qN/7Nu9Q2ony19GruqioiY+n7GX+qQc6Z5ob2GVuO9R6pK2Fb9P4F/+iQipZSqh0C/94jeMEopFVAC/U97TdpKqYCiPW2llLIRfQiCUkrZiA6PKKWUjejwiFJK2YgmbaWUshEdHlFKKRvRpK2UUjZy2t8B+JgmbaVUQNGetlJK2YgmbaWUshGdPaKUD9jxjnmh/g6gjk76OwA/0Z62UkrZiF7GrpRSNqLDI0opZSM6PKKUUjaiPW2llLIR7WkrpZSNBHpPO8jfASillDdV1KHUxhiz2Bhz2BiT51Z3qTEm2RhTZP1sbdUbY8ybxphiY0yOMaan2zaTrfWLjDGT3ep7GWNyrW3eNMbU+qBhTdpKqYAidSgeWAKMOK9uDrBZRDoDm633ACOBzlaZCiwAV5IH5gE3Ar2BeWcTvbXOQ27bnd/WBTRpK6UCypk6lNqIyBfA0fOqE4Ak63USMNqt/h1xSQNaGWPaA8OBZBE5KiLfAcnACGtZSxFJExEB3nH7rGpp0lZKBZS69LSNMVONMZluZaoHTbQVkQPW64NAW+t1JFDqtl6ZVVdTfVkV9TXSE5FKqYBSlxORIrIQWHixbYmIGGMadMKK9rSVUgHFmyciq3HIGtrA+nnYqt8HRLutF2XV1VQfVUV9jTRpK6UCipdPRFZlPXB2Bshk4H23+vusWSR9gHJrGGUjMMwY09o6ATkM2Ggt+5cxpo81a+Q+t8+qlm2S9owZM8jNzSUvL4/HHnsMgOuuu46tW7ficDjIyMjghhtu8HOU1SspKSEnJ6cy1sZu+PDhFBYWUlRUxOzZs/0dTq2ioqJISUkhPz+fvLw8ZsyY4bO2wsPDWfHuu+QUFJC9Ywc39ulzzvLx995LZnY223Ny+Oyrr/jVtdfWu83Q0FD+tnIlO4qK2JKWRkxMDADxQ4awNTOT7Tk5bM3MZOCgQfVuqzoNuY/rw5snIo0xK4CtwDXGmDJjzBTgRWCoMaYIGGK9B/gY2AMUA4uA/wsgIkeB/wYyrPJ7qw5rnbetbXYDn9QalIj4tFC3X3xVlu7du0tubq6EhYVJcHCwJCcnS6dOnWTjxo0yYsQIAWTkyJGSmppa77Z8VUpKSqRNmzZ+j8OTEhQUJMXFxRIbGyshISHidDqla9eufo+rptKuXTuJi4sTQFq0aCE7d+70esyhVnlnyRKZNmWKhII0DwmRiPDwymWhILfcdJNc3qqVhILcMWKEpKelnbO8ptI5JkY+S029oP7R6dNl4YIFEgoycdw4WbVypYSC3NCjh8S0by+hID26d5eysrLKbey4j72Rcx4C8bT4Ov/5otiip921a1fS09P58ccfqaio4PPPP2fMmDGICC1btgRcvZ/9+/f7OdLA0Lt3b4qLiykpKeHUqVOsXLmShIQEf4dVo4MHD+JwOAA4ceIEBQUFREbWeiK+zlq2bEn/W27hr4mJAJw6dYry8vJz1knbupVjx44BkJ6WRmTUf4YtJ0ycyJfp6WxzOPjft94iKMizQ/COhASWJrlmma1dvZpB8fEAZDudHDjgmsiwIz+fsLAwQkN9c+fvhtrH9eXNnnZjVOekbYx5xxeB1CQvL4/+/ftz6aWXEhYWxq233kp0dDQzZ87k5ZdfZu/evbzyyiv89re/bejQPCYibNq0iczMTB566CF/h1OjyMhISkv/M0OprKysUR6c1YmJiSEuLo709HSvf3bH2FiOHDnCor/+lfSsLBYsWkSzZs2qXf+BKVPY+InrL94uXbpw97hxDOzbl95xcVRUVDBh4kSP2r0iMpIy69+koqKCf5WX06ZNm3PWufOuu3BmZXHypO8ff+DLfVxfdena21GNU/6MMevPrwIGGWNaAYjIqGq2m4rriiCvKCwsZP78+WzatInvv/8ep9NJRUUF06dPZ9asWaxdu5a7776bxMREhg4d6q1mvapfv37s37+fiIgIkpOTKSwsZMuWLf4OK+A0b96cNWvWMHPmTI4fP+71z2/SpAlxPXsy69FHydi2jVdff53/b84cnnvmmQvWHTBwIPdPmcKgfv0AGBQfT1yvXnxtndMICwvj8GHXxINVa9fSMTaW0NBQojt0YJvVo/2fN97gnSVLao2ra7du/GH+fG4bNsxL37R6vt7H9RXoD0GobTw6C/gbMBAYYP08YL0e0FBj2ueXF154QaZPny7Hjh07p768vLzBxlDrU+bNmyePP/643+OorvTp00c2bNhQ+X7OnDkyZ84cv8dVW2nSpIls2LBBZs2a5ZPPDwWJbttWSkpKKseNB/XrJx9/+OEFY9A9f/Ur2V1cLN07d66sm/nIIzL/D3+4qDHtTRs2SP8+fSQUJCw4WI4cOVK5LDYyUnbt3CkDbr75nG3suI+9MeY7CcTT4u/xaV+MaV8PbAeewjV95TPgRxH5XEQ+r2Vbr4qIiAAgOjqaMWPGsHz5cvbv38+AAQMAGDx4MEVFRQ0ZkseaNWtGixYtKl8PGzaMvLy8Wrbyn4yMDDp37kzHjh0JCQlh/PjxrF9//h9djU9iYiIFBQW89tprPmvj0KFDlJWWcvXVVwOu3nPBjh3nrBMdHc2qtWt5YNKkc/5PpmzezJixYyv/L7du3ZoOHTp41O6H69czafJkAMaMHctnKSmA61zOex99xFNz5rD166/r/f1q0xD7uL4CfUzbo8yOa9L3u8D/AHvr8lsBL/0G/uKLLyQ/P1+cTqcMHjxYAOnbt69kZmaK0+mUtLQ06dmzp997e1WV2NhYcTqd4nQ6JS8vT+bOnev3mGorI0eOlJ07d0pxcbEt4u3bt6+IiGRnZ4vD4RCHwyEjR470ahtne7DXX3edZGZkSE52try/bp1c3qqVPDxtmjw8bZqEgiQuWiRHjx4Vp8MhTodDMjMyKre99557xOlwSE52tmzPzJR+N97oUU/7F02byupVq6S4qEi2pafLNbGxEgryzFNPyYkTJyrbcjocEhkR4ZOedkPsY2/0RO8F8bT4u9d8McVYidUjxpjbgL4iMrcO23jegFKNmD6N3fdEpNZbk9bm3jrknOVeaK+h1eneIyLyEfCRj2JRSql6s+2wh4f0hlFKqYAS6LNHNGkrpQJKoI/HatJWSgUUHR5RSikb0Z62UkrZiPa0lVLKRvREpFJK2YgOjyillI3o8IhSStmI9rSVUspGtKetlFI2oklbKaVsRJO2UkrZiCZtpRRgv1ud2u1Wst4S6EnbFk9jV0opT9XlqQu1McZ8Y4zJNcY4jTGZVt2lxphkY0yR9bO1VW+MMW8aY4qNMTnGmJ5unzPZWr/IGDO5Pt9Pk7ZSKqB4M2lbBolIDxG53no/B9gsIp2BzdZ7gJFAZ6tMBRaAK8kD84Abgd7AvLOJ/mJo0lZKBZQGeEZkApBkvU4CRrvVvyMuaUArY0x7YDiQLCJHReQ7IBkYcbGNa9JWSgWUijoUY8xUY0ymW5l63scJsMkYs91tWVsROWC9Pgi0tV5HAqVu25ZZddXVXxQ9EamUCih1uSJSRBYCC2tYpZ+I7DPGXA4kG2MKz9teGvo5uNrTVkoFFG8Oj4jIPuvnYWAdrjHpQ9awB9bPw9bq+4Bot82jrLrq6i+KJm2lVEDxVtI2xjQ3xvzi7GtgGJAHrAfOzgCZDLxvvV4P3GfNIukDlFvDKBuBYcaY1tYJyGFW3UXR4RGlVEDx4lhFW2CdMQZcuXK5iGwwxmQAq4wxU4B/APdY638M3AoUAz8ADwCIyFFjzH8DGdZ6vxeRoxcblBHx7XBMQ4/3KKVc7HhxzU8ipr6fcW0dck6OF9praNrTVkoFlEDvJWrSVkoFlEC/jF2TtlIqoGhPWymlbCTQe9oNNuUvMTGRQ4cOkZubW+Xya665hq+//pp///vfPP74415pMzQ0lJUrV1JUVERaWhoxMTEADBkyhMzMTHJycsjMzGTQoEFeac9dVd/397//PdnZ2TgcDjZu3Ej79u293q63DB8+nMLCQoqKipg9e7a/w/GIHWMuKSkhJycHh8NBRkZG7RtcpJ0lJWzPyWGbw8HX1bRzy4ABbHM4cOTlkfzZZ/VuMzQ0lL+tXMmOoiK2uB1/8UOGsDUzk+05OWzNzGSgl48/H9x7pHEREZ8WrP3Tv39/iYuLk9zc3Cr3X0REhFx//fXy/PPPy+OPP16X/S4xMTGSmpp6Qf306dNlwYIFAsi4ceNk5cqVAkiPHj2kffv2Akj37t2lrKysTu15Uqr6vr/4xS8qXz/66KOVsTW2EhQUJMXFxRIbGyshISHidDqla9eufo8r0GIGpKSkRNq0aeOTzw51KyUlJdK+TZtz6txLRHi47MjPl07R0RIKEhkRUe2655fOMTHyWWrqBfWPTp8uCxcskFCQiePGyaqVKyUU5IYePSSmfXsJBelhHX9nt/FGzukE4mnxdf7zRWmwnvaWLVs4erT6qYlHjhwhMzOTU6dOXbBs4sSJpKen43A4eOuttwgK8izshIQEkpJc93VZvXo18fHxADidTg4ccN06ID8/n7CwMEJDvTtBqqrve/z48crXzZs3P/tLrdHp3bs3xcXFlJSUcOrUKVauXElCQoK/w6qRHWNuTMbfey/vrV1LaanrFhlHjhypXDZh4kS+TE9nm8PB/9bh+LsjIYGl1vG3dvVqBlnHX7bb8bfDB8dfA9wwyq/qlLSNMf2MMb8xxgzzVUDn69KlC+PGjaNv377ExcVRUVHBxIkTPdo2MjKy8j9hRUUF5eXltGnT5px17rrrLrKysjh5smFucf/888+zd+9eJk6cyDPPPNMgbdaV+34DKCsrIzLyou9v0yDsGDOAiLBp0yYyMzN56KGHfNkQH23axNbMTKZU0U7nq6+mdevWbEpNZWtmJhMnTQJcx9/d48YxsG9felvH3wQPj78rIiMpczv+/lXF8XfnXXfh9PLxV5c/R+yoxhORxphtItLbev0Q8DCu6+/nGWN6isiL1Ww3Fdf9ZOstPj6eXr16VY73hYWFcfiw61L/tWvXEhsbS2hoKB06dMDhcADwxhtvsGTJklo/u1u3bsyfP59hwxrsdxBPP/00Tz/9NHPmzOGRRx7h2WefbbC2VePTr18/9u/fT0REBMnJyRQWFrJlyxavtzPIrZ2Pk5PZWVjIl27tNGnShLhevRgRH09YWBhfbN3KtrQ0BsXHE9erV+U4uPvxt2rtWjpax190hw5ss46//3njDd7x4Pjr2q0bf5g/n9u8fPzZtQftqdpmj4S4vZ4KDBWRI8aYV4A0oMqk7X7nrPpeEWmMISkpiblz516wbMyYMQDExMSwZMmSC04o7tu3j+joaPbt20dwcDDh4eF8++23gKtntm7dOu677z727NlTnxAvyrJly/j4448bZdI+u9/OioqKYt++i76/TYOwY8wA+/fvB1zDEevWraN3794+Sdru7by/bh039O59TtIuKyvj22+/5YcffuCHH35gyxdf8KvrrsMYw9+SkvhdFcffPW7H36IlSxh23vG3f98+otyOv5bnHX/vrlvHgz44/gI9adc2PBJk3eSkDa5L3o8AiMj3wGmfRwds3ryZsWPHEhERAUDr1q3p0KGDR9uuX7+eyZMnAzB27FhSUlIACA8P56OPPmLOnDl8/fXXvgm8CldddVXl64SEBAoLC2tY238yMjLo3LkzHTt2JCQkhPHjx7N+/Xp/h1UjO8bcrFkzWrRoUfl62LBh5OXl+bydIcOGkX9eOx++/z59+/UjODiYsLAwet94I4UFBaRs3syYizz+Ply/nknW8Tdm7Fg+czv+3vvoI56aM4etPjj+An14pLaZH98Ae4AS62d7q74F4KzL7JHly5fL/v375eTJk1JaWioPPvigTJs2TaZNmyaAtG3bVkpLS6W8vFy+++47KS0trZxtcc8994jD4ZDs7GzJzMyUG2+88Zx9X93skaZNm8qqVaukqKhI0tPTJTY2VgB56qmn5MSJE+JwOCpLRESEV8/cV/V9V69eLbm5uZKdnS3r16+XK664wu+zF6orI0eOlJ07d0pxcbHMnTvX7/EEYsyxsbHidDrF6XRKXl6e12M+OyPjmthYyXY6JdvplPy8PPnd3LkSCvLwtGny8LRplevNeeIJ2ZGfL3m5ufL4Y49V1t97zz3idDgkJztbtmdmSr8bb/Ro9sgvmjaV1atWSXFRkWxLT5drYmMlFOQZ6/hzOhyV5exsFW/MrmgH4mnx90yQiykXdcMoY0wzXE9vKPFg3bo3oJSqt5/rDaPa1iHnHPq53DBKRH7A1ftWSqlGJdB7iXoZu1IqoGjSVkopGwn02SOatJVSAaXC3wH4mCZtpVRA0eERpZSyER0eUUopG9GetlJK2Yj2tJVSyka0p62UUjYS6LNHGuwhCEop1RC8+RAEY8wIY8xOY0yxMWaOj0Kuk4u690idGtB7jyjlFz/Xe48E1yHnVNTQnjEmGNgFDAXKgAxggojsqG+M9aE9baVUQPFiT7s3UCwie0TkJLASSPBJ0HXg8zFt8eFdtIwxU60HLtiC3eIF+8Vst3hBY/a2uuScKp6ytdDte0UCpW7LyoAb6x9h/di9p+2VR5o1ILvFC/aL2W7xgsbsNyKyUESudyuN8heRO7snbaWU8pV9QLTb+yirzq80aSulVNUygM7GmFhjTCgwHvD7M+zsPk+70f8pcx67xQv2i9lu8YLG3CiJyGljzCPARiAYWCwi+X4Oy/dT/pRSSnmPDo8opZSNaNJWSikbsWXSboyXltbEGLPYGHPYGJPn71g8YYyJNsakGmN2GGPyjTGP+Tum2hhjLjHGbDPGZFsxP+fvmDxhjAk2xjiMMR/6OxZPGGO+McbkGmOcxphMf8fzc2S7Me3GemlpTYwxtwAngHdE5Jf+jqc2xpj2QHsRyTLG/ALYDoxu5PvYAM1F5IQxJgT4EnhMRNL8HFqNjDG/Aa4HWorI7f6OpzbGmG+A60Xkn/6O5efKjj3tRnlpaU1E5AvgqL/j8JSIHBCRLOv1caAA19VhjZa4nLDehlilUfdIjDFRwG3A2/6ORdmHHZN2VZeWNuqEYmfGmI5AHJDu51BqZQ01OIHDQLKINPaYXweexF737RdgkzFmu3UJuGpgdkzaqoEYY1oAa4CZIvIvf8dTGxGpEJEeuK5c622MabRDUcaY24HDIrLd37HUUT8R6QmMBB62hv5UA7Jj0m6Ul5YGGmtceA2wTETW+jueuhCRY0AqMMLPodSkLzDKGiNeCQw2xvzNvyHVTkT2WT8PA+twDVeqBmTHpN0oLy0NJNZJvUSgQET+5O94PGGMiTDGtLJeh+E6UV3o16BqICK/FZEoEemI6/9wioj8l5/DqpExprl1YhpjTHNgGGCLGVGBxHZJW0ROA2cvLS0AVjWGS0trYoxZAWwFrjHGlBljpvg7plr0BSbh6v05rXKrv4OqRXsg1RiTg+sXe7KI2GIanY20Bb40xmQD24CPRGSDn2P62bHdlD+llPo5s11PWymlfs40aSullI1o0lZKKRvRpK2UUjaiSVsppWxEk7ZSStmIJm2llLKR/x9aAqeJe3rmXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# валидация + MultiCollinearityEliminator порог коллинеарности 0.75 + oversampling + sampling_strategy + svd2\n",
    "report = classification_report(Y_val, model.predict(X_val))\n",
    "print(report)\n",
    "print(f\"Метрика: {0.2* recall_score(Y_val, model.predict(X_val), average='macro') + 0.8* precision_score(Y_val, model.predict(X_val), average='macro')}\")\n",
    "\n",
    "# посмотрим как ошибается модель\n",
    "heat_map = np.zeros((6,6))\n",
    "for (y, y_pred) in zip(Y_val.values.astype(int), model.predict(X_val).astype(int)):\n",
    "    heat_map[y][y_pred] += 1\n",
    "sns.heatmap(heat_map, annot=True, cmap=\"gist_heat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f282f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    139438\n",
      "         1.0       1.00      1.00      1.00     10772\n",
      "         2.0       1.00      1.00      1.00      1440\n",
      "         3.0       1.00      1.00      1.00      2428\n",
      "         4.0       1.00      1.00      1.00      2932\n",
      "         5.0       1.00      1.00      1.00      2990\n",
      "\n",
      "    accuracy                           1.00    160000\n",
      "   macro avg       1.00      1.00      1.00    160000\n",
      "weighted avg       1.00      1.00      1.00    160000\n",
      "\n",
      "Метрика: 0.999695706833492\n"
     ]
    }
   ],
   "source": [
    "# тренировочная выборка\n",
    "report = classification_report(Y_train, model.predict(X_train))\n",
    "print(report)\n",
    "print(f\"Метрика: {0.2* recall_score(Y_train, model.predict(X_train), average='macro') + 0.8* precision_score(Y_train, model.predict(X_train), average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091ab0d",
   "metadata": {},
   "source": [
    "# Sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2c2dce0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2561632341.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = XY_train.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2561632341.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = XY_test.drop(['target'], 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим выборки\n",
    "XY_train = train[train['train'] == 1].drop('train', axis=1)\n",
    "XY_test = train[train['train'] == 0].drop('train', axis=1)\n",
    "\n",
    "X_train = XY_train.drop(['target'], 1)\n",
    "Y_train = XY_train['target']\n",
    "\n",
    "X_test = XY_test.drop(['target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bf4a18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_vars = ['program_id', 'student_id', 'communication_type', 'ABC', 'city', 'country', 'os', 'browser', \\\n",
    "                   'platform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d475be33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/218761128.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return X.drop(X_obj.columns,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/1999260008.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = X_train.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/1999260008.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(categorial_vars,1)\n"
     ]
    }
   ],
   "source": [
    "one_hot_target_encoder = OneHotTargetEncoder()\n",
    "\n",
    "one_hot_target_encoder.fit(X_train[categorial_vars], Y_train)\n",
    "\n",
    "X_train = pd.concat([X_train, one_hot_target_encoder.transform(X_train[categorial_vars])], axis=1)\n",
    "X_test = pd.concat([X_test, one_hot_target_encoder.transform(X_test[categorial_vars])], axis=1)\n",
    "\n",
    "X_train = X_train.drop(categorial_vars,1)\n",
    "X_test = X_test.drop(categorial_vars,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "66e3d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2153210587.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23172/2153210587.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test.drop(un_selected_features, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(un_selected_features, 1, inplace=True)\n",
    "X_test.drop(un_selected_features, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e4283e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=11, n_estimators=180, tree_method='gpu_hist', n_jobs=-1, reg_lambda = 0, reg_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d03a51db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=1, ...)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, sample_weight=my_sample_weights(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "01b26ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution = pd.read_csv('sample_solution.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8dff1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution['target'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "73b238f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution.to_csv('sample_solution_sas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21b8d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution_sas = pd.read_csv('sample_solution_sas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5580678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84992</th>\n",
       "      <td>186427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84993</th>\n",
       "      <td>197918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84994</th>\n",
       "      <td>174961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84995</th>\n",
       "      <td>182226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84996</th>\n",
       "      <td>95178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target\n",
       "0       77551       0\n",
       "1      227812       0\n",
       "2      103035       0\n",
       "3      260943       0\n",
       "4      134611       0\n",
       "...       ...     ...\n",
       "84992  186427       0\n",
       "84993  197918       0\n",
       "84994  174961       0\n",
       "84995  182226       0\n",
       "84996   95178       0\n",
       "\n",
       "[84997 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_solution_sas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
