{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef289504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score, classification_report, precision_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from boruta import BorutaPy\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7d808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_dataset_train.csv')\n",
    "test = pd.read_csv('test_dataset_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3219421",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf117a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age_indicator</th>\n",
       "      <th>month_id</th>\n",
       "      <th>student_id</th>\n",
       "      <th>program_id</th>\n",
       "      <th>carts_created_at</th>\n",
       "      <th>spent_time_total</th>\n",
       "      <th>spent_time_to_complete_hw</th>\n",
       "      <th>completed_hw</th>\n",
       "      <th>failed_hw</th>\n",
       "      <th>reworked_hw</th>\n",
       "      <th>interacted_hw</th>\n",
       "      <th>avg_hw_mark</th>\n",
       "      <th>test_with_good_mark</th>\n",
       "      <th>test_with_great_mark</th>\n",
       "      <th>webinars</th>\n",
       "      <th>avg_quiz_result</th>\n",
       "      <th>notes</th>\n",
       "      <th>hw_leader</th>\n",
       "      <th>lessons</th>\n",
       "      <th>activity</th>\n",
       "      <th>bought_d1</th>\n",
       "      <th>bought_d2</th>\n",
       "      <th>bought_d3</th>\n",
       "      <th>bought_d4</th>\n",
       "      <th>bought_d5</th>\n",
       "      <th>bought_avg_duration</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>promo</th>\n",
       "      <th>price</th>\n",
       "      <th>communication_type</th>\n",
       "      <th>auto_payment</th>\n",
       "      <th>ABC</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "      <th>speed_recall</th>\n",
       "      <th>os</th>\n",
       "      <th>browser</th>\n",
       "      <th>platform</th>\n",
       "      <th>m_avg_talk_duration</th>\n",
       "      <th>m_avg_duration</th>\n",
       "      <th>m_missed_calls</th>\n",
       "      <th>m_total_calls</th>\n",
       "      <th>m_was_conversations</th>\n",
       "      <th>m_total_duration</th>\n",
       "      <th>p_avg_talk_duration</th>\n",
       "      <th>p_avg_duration</th>\n",
       "      <th>p_missed_calls</th>\n",
       "      <th>p_total_calls</th>\n",
       "      <th>p_was_conversations</th>\n",
       "      <th>p_total_duration</th>\n",
       "      <th>support_feedback_avg</th>\n",
       "      <th>feedback_avg_d1</th>\n",
       "      <th>feedback_avg_d2</th>\n",
       "      <th>feedback_avg_d3</th>\n",
       "      <th>feedback_avg_d4</th>\n",
       "      <th>feedback_avg_d5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15182</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9/30/2020</td>\n",
       "      <td>6694527</td>\n",
       "      <td>1469</td>\n",
       "      <td>8/26/2020</td>\n",
       "      <td>163.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>20042.959300</td>\n",
       "      <td>phone</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2021</td>\n",
       "      <td>6712877</td>\n",
       "      <td>1392</td>\n",
       "      <td>8/5/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>15057.315000</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47931</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2/28/2021</td>\n",
       "      <td>6659444</td>\n",
       "      <td>376</td>\n",
       "      <td>6/20/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>23389.029300</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11/30/2021</td>\n",
       "      <td>7151591</td>\n",
       "      <td>1160</td>\n",
       "      <td>4/14/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>22260.632220</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>pc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7806</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10/31/2020</td>\n",
       "      <td>6705666</td>\n",
       "      <td>952</td>\n",
       "      <td>7/19/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>7255.515915</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>179932</td>\n",
       "      <td>27.0</td>\n",
       "      <td>11/30/2021</td>\n",
       "      <td>6816668</td>\n",
       "      <td>1043</td>\n",
       "      <td>10/16/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>10263.967450</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>257734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9/30/2021</td>\n",
       "      <td>6984939</td>\n",
       "      <td>1635</td>\n",
       "      <td>1/2/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>35998.565400</td>\n",
       "      <td>order</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iOS</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>43549</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3/31/2021</td>\n",
       "      <td>6670084</td>\n",
       "      <td>789</td>\n",
       "      <td>6/29/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>+</td>\n",
       "      <td>22084.062000</td>\n",
       "      <td>web</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>100800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6/30/2021</td>\n",
       "      <td>6917324</td>\n",
       "      <td>476</td>\n",
       "      <td>12/7/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>14377.805400</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Android</td>\n",
       "      <td>Samsung Internet</td>\n",
       "      <td>mobile</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>162913</td>\n",
       "      <td>18.0</td>\n",
       "      <td>10/31/2021</td>\n",
       "      <td>7057970</td>\n",
       "      <td>1104</td>\n",
       "      <td>2/24/2021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "      <td>55596.240000</td>\n",
       "      <td>order</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mac OS X</td>\n",
       "      <td>Safari</td>\n",
       "      <td>pc</td>\n",
       "      <td>69.5</td>\n",
       "      <td>69.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  age_indicator    month_id  student_id  program_id  \\\n",
       "0        15182           32.0   9/30/2020     6694527        1469   \n",
       "1        89385            NaN   6/30/2021     6712877        1392   \n",
       "2        47931            NaN   2/28/2021     6659444         376   \n",
       "3       279085            1.0  11/30/2021     7151591        1160   \n",
       "4         7806           30.0  10/31/2020     6705666         952   \n",
       "...        ...            ...         ...         ...         ...   \n",
       "199995  179932           27.0  11/30/2021     6816668        1043   \n",
       "199996  257734            NaN   9/30/2021     6984939        1635   \n",
       "199997   43549           17.0   3/31/2021     6670084         789   \n",
       "199998  100800            NaN   6/30/2021     6917324         476   \n",
       "199999  162913           18.0  10/31/2021     7057970        1104   \n",
       "\n",
       "       carts_created_at  spent_time_total  spent_time_to_complete_hw  \\\n",
       "0             8/26/2020             163.0                        0.0   \n",
       "1              8/5/2020               NaN                        NaN   \n",
       "2             6/20/2020               NaN                        NaN   \n",
       "3             4/14/2021               NaN                        NaN   \n",
       "4             7/19/2020               NaN                        NaN   \n",
       "...                 ...               ...                        ...   \n",
       "199995       10/16/2020               NaN                        NaN   \n",
       "199996         1/2/2021               NaN                        NaN   \n",
       "199997        6/29/2020               NaN                        NaN   \n",
       "199998        12/7/2020               NaN                        NaN   \n",
       "199999        2/24/2021               NaN                        NaN   \n",
       "\n",
       "        completed_hw  failed_hw  reworked_hw  interacted_hw  avg_hw_mark  \\\n",
       "0                1.0        0.0         17.0            3.0        100.0   \n",
       "1                NaN        NaN          NaN            NaN          NaN   \n",
       "2                NaN        NaN          NaN            NaN          NaN   \n",
       "3                NaN        NaN          NaN            NaN          NaN   \n",
       "4                NaN        NaN          NaN            NaN          NaN   \n",
       "...              ...        ...          ...            ...          ...   \n",
       "199995           NaN        NaN          NaN            NaN          NaN   \n",
       "199996           NaN        NaN          NaN            NaN          NaN   \n",
       "199997           0.0        0.0          0.0            2.0          NaN   \n",
       "199998           NaN        NaN          NaN            NaN          NaN   \n",
       "199999           NaN        NaN          NaN            NaN          NaN   \n",
       "\n",
       "        test_with_good_mark  test_with_great_mark  webinars  avg_quiz_result  \\\n",
       "0                      12.0                   8.0       0.0              NaN   \n",
       "1                       NaN                   NaN       NaN              NaN   \n",
       "2                       NaN                   NaN       NaN              NaN   \n",
       "3                       NaN                   NaN       NaN              NaN   \n",
       "4                       NaN                   NaN       NaN              NaN   \n",
       "...                     ...                   ...       ...              ...   \n",
       "199995                  NaN                   NaN       NaN              NaN   \n",
       "199996                  NaN                   NaN       NaN              NaN   \n",
       "199997                  0.0                   0.0       0.0              NaN   \n",
       "199998                  NaN                   NaN       NaN              NaN   \n",
       "199999                  NaN                   NaN       NaN              NaN   \n",
       "\n",
       "        notes  hw_leader  lessons  activity  bought_d1  bought_d2  bought_d3  \\\n",
       "0       147.0        0.0     14.0      32.0          0          0          0   \n",
       "1         NaN        NaN      NaN       NaN          0          0          0   \n",
       "2         NaN        NaN      NaN       NaN          0          0          0   \n",
       "3         NaN        NaN      NaN       NaN          0          0          0   \n",
       "4         NaN        NaN      NaN       NaN          0          0          0   \n",
       "...       ...        ...      ...       ...        ...        ...        ...   \n",
       "199995    NaN        NaN      NaN       NaN          1          0          0   \n",
       "199996    NaN        NaN      NaN       NaN          0          0          0   \n",
       "199997    0.0        0.0      2.0       0.0          0          0          0   \n",
       "199998    NaN        NaN      NaN       NaN          0          0          0   \n",
       "199999    NaN        NaN      NaN       NaN          0          0          0   \n",
       "\n",
       "        bought_d4  bought_d5  bought_avg_duration  payment_type promo  \\\n",
       "0               0          0                  NaN             1     +   \n",
       "1               0          0                  NaN             1     -   \n",
       "2               0          0                  NaN             1     +   \n",
       "3               0          0                  NaN             1     -   \n",
       "4               0          0                  NaN             1     -   \n",
       "...           ...        ...                  ...           ...   ...   \n",
       "199995          1          0                 40.0             1     +   \n",
       "199996          0          0                  NaN             1     -   \n",
       "199997          0          0                  NaN             1     +   \n",
       "199998          0          0                  NaN             1     -   \n",
       "199999          0          0                  NaN             1     -   \n",
       "\n",
       "               price communication_type  auto_payment ABC city country  \\\n",
       "0       20042.959300              phone             0   D  NaN     NaN   \n",
       "1       15057.315000              order             1   A  NaN     NaN   \n",
       "2       23389.029300                web             0   D  NaN     NaN   \n",
       "3       22260.632220              order             1   B  NaN     NaN   \n",
       "4        7255.515915              order             1   A  NaN     NaN   \n",
       "...              ...                ...           ...  ..  ...     ...   \n",
       "199995  10263.967450              order             1   D  NaN     NaN   \n",
       "199996  35998.565400              order             0   D  NaN     NaN   \n",
       "199997  22084.062000                web             0   D  NaN     NaN   \n",
       "199998  14377.805400              order             1   A  NaN     NaN   \n",
       "199999  55596.240000              order             1   A  NaN     NaN   \n",
       "\n",
       "        gender  speed_recall        os           browser platform  \\\n",
       "0          1.0           NaN       NaN               NaN      NaN   \n",
       "1          0.0           1.0       NaN               NaN      NaN   \n",
       "2          0.0           NaN       NaN               NaN      NaN   \n",
       "3          1.0           NaN   Windows            Chrome       pc   \n",
       "4          1.0           NaN       NaN               NaN      NaN   \n",
       "...        ...           ...       ...               ...      ...   \n",
       "199995     1.0           NaN       NaN               NaN      NaN   \n",
       "199996     0.0           NaN       iOS     Mobile Safari   mobile   \n",
       "199997     1.0           NaN       NaN               NaN      NaN   \n",
       "199998     0.0           NaN   Android  Samsung Internet   mobile   \n",
       "199999     1.0           NaN  Mac OS X            Safari       pc   \n",
       "\n",
       "        m_avg_talk_duration  m_avg_duration  m_missed_calls  m_total_calls  \\\n",
       "0                       NaN             NaN             NaN            NaN   \n",
       "1                       NaN             NaN             NaN            NaN   \n",
       "2                       NaN             NaN             NaN            NaN   \n",
       "3                       NaN             NaN             NaN            NaN   \n",
       "4                       NaN             NaN             NaN            NaN   \n",
       "...                     ...             ...             ...            ...   \n",
       "199995                  0.0             NaN             3.0            3.0   \n",
       "199996                  NaN             NaN             NaN            NaN   \n",
       "199997                  NaN             NaN             NaN            NaN   \n",
       "199998                  6.0             6.0             0.0            1.0   \n",
       "199999                 69.5            69.5             0.0            2.0   \n",
       "\n",
       "        m_was_conversations  m_total_duration  p_avg_talk_duration  \\\n",
       "0                       NaN               NaN                  NaN   \n",
       "1                       NaN               NaN                  NaN   \n",
       "2                       NaN               NaN                  NaN   \n",
       "3                       NaN               NaN                  NaN   \n",
       "4                       NaN               NaN                  NaN   \n",
       "...                     ...               ...                  ...   \n",
       "199995                  0.0               0.0                  NaN   \n",
       "199996                  NaN               NaN                  NaN   \n",
       "199997                  NaN               NaN                  NaN   \n",
       "199998                  1.0               6.0                  NaN   \n",
       "199999                  2.0             139.0                  NaN   \n",
       "\n",
       "        p_avg_duration  p_missed_calls  p_total_calls  p_was_conversations  \\\n",
       "0                  NaN             NaN            NaN                  NaN   \n",
       "1                  NaN             NaN            NaN                  NaN   \n",
       "2                  NaN             NaN            NaN                  NaN   \n",
       "3                  NaN             NaN            NaN                  NaN   \n",
       "4                  NaN             NaN            NaN                  NaN   \n",
       "...                ...             ...            ...                  ...   \n",
       "199995             NaN             NaN            NaN                  NaN   \n",
       "199996             NaN             NaN            NaN                  NaN   \n",
       "199997             NaN             NaN            NaN                  NaN   \n",
       "199998             NaN             NaN            NaN                  NaN   \n",
       "199999             NaN             NaN            NaN                  NaN   \n",
       "\n",
       "        p_total_duration  support_feedback_avg  feedback_avg_d1  \\\n",
       "0                    NaN                   4.0              5.0   \n",
       "1                    NaN                   NaN              NaN   \n",
       "2                    NaN                   NaN              NaN   \n",
       "3                    NaN                   NaN              NaN   \n",
       "4                    NaN                   NaN              5.0   \n",
       "...                  ...                   ...              ...   \n",
       "199995               NaN                   5.0              NaN   \n",
       "199996               NaN                   NaN              4.5   \n",
       "199997               NaN                   3.0              NaN   \n",
       "199998               NaN                   NaN              NaN   \n",
       "199999               NaN                   NaN              NaN   \n",
       "\n",
       "        feedback_avg_d2  feedback_avg_d3  feedback_avg_d4  feedback_avg_d5  \\\n",
       "0                   NaN              NaN              NaN              NaN   \n",
       "1                   NaN              NaN              NaN              NaN   \n",
       "2                   NaN              NaN              NaN              NaN   \n",
       "3                   NaN              NaN              NaN              NaN   \n",
       "4                   NaN              NaN              NaN              NaN   \n",
       "...                 ...              ...              ...              ...   \n",
       "199995              NaN              NaN              NaN              NaN   \n",
       "199996              NaN              NaN              NaN              NaN   \n",
       "199997              NaN              NaN              4.0              NaN   \n",
       "199998              NaN              NaN              NaN              NaN   \n",
       "199999              NaN              NaN              NaN              NaN   \n",
       "\n",
       "        target  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "199995       0  \n",
       "199996       0  \n",
       "199997       0  \n",
       "199998       0  \n",
       "199999       0  \n",
       "\n",
       "[200000 rows x 59 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce654922",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39778efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# вспомогательный флаг тренировочного и тестовой частей общего набора данных\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "# объединение в один датасет\n",
    "train = pd.concat([train, test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2d0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# некоторые колонки с количественными переменными следует заполнить нулями,\n",
    "# а некоторые заполнить \"типичным\" значением\n",
    "cols_to_fill_with_zero = ['avg_quiz_result', 'bought_avg_duration', 'speed_recall', 'm_avg_talk_duration', 'm_avg_duration', \\\n",
    "                          'm_missed_calls', 'm_total_calls', 'm_was_conversations', 'm_total_duration', 'p_avg_talk_duration', \\\n",
    "                          'p_avg_duration', 'p_missed_calls', 'p_total_calls', 'p_was_conversations', 'p_total_duration', \\\n",
    "                          'support_feedback_avg', 'feedback_avg_d1', 'feedback_avg_d2', 'feedback_avg_d3', 'feedback_avg_d4', \\\n",
    "                          'feedback_avg_d5', 'avg_hw_mark']\n",
    "cols_to_fill_with_avg = ['age_indicator', 'spent_time_total', 'spent_time_to_complete_hw', 'completed_hw', \\\n",
    "                         'failed_hw', 'reworked_hw', 'interacted_hw', 'test_with_good_mark', \\\n",
    "                         'test_with_great_mark', 'webinars', 'notes', 'hw_leader', \\\n",
    "                         'lessons', 'activity', 'bought_d1', 'bought_d2', 'bought_d3', 'bought_d4', \\\n",
    "                         'bought_d5', 'price', 'gender']\n",
    "\n",
    "cols_to_fill_with_nan = ['communication_type', 'city', 'country', 'os', 'browser', 'platform']\n",
    "\n",
    "for i in cols_to_fill_with_zero:\n",
    "    train.fillna({i: 0}, inplace=True)\n",
    "\n",
    "for i in cols_to_fill_with_avg:\n",
    "    train.fillna({i: train[i].median()}, inplace=True)\n",
    "\n",
    "for i in cols_to_fill_with_nan:\n",
    "    train.fillna({i: 'None'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def3c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведём колонку в формат datetime и возьмём из неё только месяц\n",
    "train['month_id'] = pd.to_datetime(train['month_id'], format = \"%m/%d/%Y\")\n",
    "train['day_id'] = pd.DatetimeIndex(train['month_id']).day\n",
    "train['day_of_week_id'] = pd.DatetimeIndex(train['month_id']).day_of_week\n",
    "train['month_id'] = pd.DatetimeIndex(train['month_id']).month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23bb5243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/2451815549.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train = train.drop(['carts_created_at'],1)\n"
     ]
    }
   ],
   "source": [
    "# переведём колонку в формат datetime\n",
    "train['carts_created_at'] = pd.to_datetime(train['carts_created_at'], format = \"%m/%d/%Y\")\n",
    "train['carts_created_at_month'] = pd.DatetimeIndex(train['carts_created_at']).month\n",
    "train['carts_created_at_day'] = pd.DatetimeIndex(train['carts_created_at']).day\n",
    "train['carts_created_at_day_of_week'] = pd.DatetimeIndex(train['carts_created_at']).day_of_week\n",
    "train = train.drop(['carts_created_at'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8853b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/44424804.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  train = train.drop(['spent_time_to_complete_hw'], 1)\n"
     ]
    }
   ],
   "source": [
    "# удалим переменные не содержащие информации\n",
    "train = train.drop(['spent_time_to_complete_hw'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01e682bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в нужный формат\n",
    "def promo(x):\n",
    "    if x == '+':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "train['promo'] = train['promo'].map(lambda x: promo(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0852b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/1474686982.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = XY_train.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/1474686982.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = XY_val.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/1474686982.py:12: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = XY_test.drop(['target'], 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим выборки\n",
    "XY_train = train[train['train'] == 1].drop('train', axis=1)\n",
    "XY_test = train[train['train'] == 0].drop('train', axis=1)\n",
    "XY_train, XY_val = train_test_split(XY_train, test_size=0.2, random_state=23)\n",
    "\n",
    "X_train = XY_train.drop(['target'], 1)\n",
    "Y_train = XY_train['target']\n",
    "\n",
    "X_val = XY_val.drop(['target'], 1)\n",
    "Y_val = XY_val['target']\n",
    "\n",
    "X_test = XY_test.drop(['target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f170d350",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_vars = ['program_id', 'student_id', 'communication_type', 'ABC', 'city', 'country', 'os', 'browser', \\\n",
    "                   'platform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d19dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotTargetEncoder():\n",
    "    def __init__(self, class_names = None, target_encoders = {}):\n",
    "        self.target_encoders = target_encoders\n",
    "        self.class_names = class_names\n",
    "    def fit(self, X, y):\n",
    "        y=y.astype(str)\n",
    "        enc = OneHotEncoder(handle_unknown='ignore')\n",
    "        y_onehot = pd.DataFrame(enc.fit_transform(pd.DataFrame(Y_train)).toarray())\n",
    "        self.class_names=y_onehot.columns\n",
    "        for class_ in self.class_names:\n",
    "            enc=ce.CatBoostEncoder()\n",
    "            enc.fit(X,y_onehot[class_]) #convert all categorical\n",
    "            self.target_encoders[class_] = enc\n",
    "    def transform(self, X):\n",
    "        X_obj=X\n",
    "        for class_ in self.class_names:\n",
    "            X_temp = self.target_encoders[class_].transform(X_obj)\n",
    "            X_temp.columns = [str(i)+'_'+str(class_) for i in X_temp.columns]\n",
    "            X = pd.concat([X,X_temp],axis=1)\n",
    "        return X.drop(X_obj.columns,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25d9e1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/218761128.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return X.drop(X_obj.columns,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2393891689.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = X_train.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2393891689.py:10: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = X_val.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2393891689.py:11: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(categorial_vars,1)\n"
     ]
    }
   ],
   "source": [
    "one_hot_target_encoder = OneHotTargetEncoder()\n",
    "\n",
    "one_hot_target_encoder.fit(X_train[categorial_vars], Y_train)\n",
    "\n",
    "X_train = pd.concat([X_train, one_hot_target_encoder.transform(X_train[categorial_vars])], axis=1)\n",
    "X_val = pd.concat([X_val, one_hot_target_encoder.transform(X_val[categorial_vars])], axis=1)\n",
    "X_test = pd.concat([X_test, one_hot_target_encoder.transform(X_test[categorial_vars])], axis=1)\n",
    "\n",
    "X_train = X_train.drop(categorial_vars,1)\n",
    "X_val = X_val.drop(categorial_vars,1)\n",
    "X_test = X_test.drop(categorial_vars,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b959d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Источник: stackoverflow\n",
    "# Feature selection class to eliminate multicollinearity\n",
    "# Выбор и удаление признаков скоррелированных между собой (борьба с мультиколлинеарносстью)\n",
    "class MultiCollinearityEliminator():\n",
    "\n",
    "    # Class initialisation\n",
    "    # Инициализация класса\n",
    "    def __init__(self, df, target, threshold=0.5):\n",
    "        self.df = df\n",
    "        self.target = target\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # Method to create and return the feature correlation matrix dataframe\n",
    "    # Метод создающий и возращающий корреляционную матрицу признаков датафрейма\n",
    "    def createCorrMatrix(self, include_target=False):\n",
    "        # Checking we should include the target in the correlation matrix\n",
    "        if (include_target == False):\n",
    "            #df_temp = self.df.drop([self.target], axis=1)\n",
    "            df_temp = self.df\n",
    "\n",
    "            # Setting method to Pearson to prevent issues in case the default method for df.corr() gets changed\n",
    "            # Setting min_period to 30 for the sample size to be statistically significant (normal) according to\n",
    "            # central limit theorem\n",
    "            corrMatrix = df_temp.corr(method='pearson', min_periods=30).abs()\n",
    "\n",
    "        # Target is included for creating the series of feature to target correlation - Please refer the notes under the\n",
    "        # print statement to understand why we create the series of feature to target correlation\n",
    "        elif (include_target == True):\n",
    "            corrMatrix = self.df.corr(method='pearson', min_periods=30).abs()\n",
    "\n",
    "        return corrMatrix\n",
    "\n",
    "    # Method to create and return the feature to target correlation matrix dataframe\n",
    "    # Метод создающий и возвращающий корреляционную матрицу признаков с целевой переменной\n",
    "    def createCorrMatrixWithTarget(self):\n",
    "\n",
    "        # After obtaining the list of correlated features, this method will help to view which variables\n",
    "        # (in the list of correlated features) are least correlated with the target\n",
    "        # This way, out the list of correlated features, we can ensure to elimate the feature that is\n",
    "        # least correlated with the target\n",
    "        # This not only helps to sustain the predictive power of the model but also helps in reducing model complexity\n",
    "\n",
    "        # Obtaining the correlation matrix of the dataframe (along with the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target=True)\n",
    "\n",
    "        # Creating the required dataframe, then dropping the target row\n",
    "        # and sorting by the value of correlation with target (in asceding order)\n",
    "        corrWithTarget = pd.DataFrame(corrMatrix.loc[:, self.target]).drop(\n",
    "            [self.target], axis=0).sort_values(by=self.target)\n",
    "        #print(corrWithTarget, '\\n')\n",
    "        return corrWithTarget\n",
    "\n",
    "    # Method to create and return the list of correlated features\n",
    "    # Метод создающий и вовзращающий лист скоррелированных признаков\n",
    "    def createCorrelatedFeaturesList(self):\n",
    "        # Obtaining the correlation matrix of the dataframe (without the target)\n",
    "        corrMatrix = self.createCorrMatrix(include_target=False)\n",
    "        colCorr = []\n",
    "        # Iterating through the columns of the correlation matrix dataframe\n",
    "        for column in corrMatrix.columns:\n",
    "            # Iterating through the values (row wise) of the correlation matrix dataframe\n",
    "            for idx, row in corrMatrix.iterrows():\n",
    "                if(row[column] > self.threshold) and (row[column] < 1):\n",
    "                    # Adding the features that are not already in the list of correlated features\n",
    "                    if (idx not in colCorr):\n",
    "                        colCorr.append(idx)\n",
    "                    if (column not in colCorr):\n",
    "                        colCorr.append(column)\n",
    "        #print(colCorr, '\\n')\n",
    "        return colCorr\n",
    "\n",
    "    # Method to eliminate the least important features from the list of correlated features\n",
    "    # Метод удаляющий наименее важные признаки (наименее скоррелированные с целевым признаком) из двух скоррелированных признаков\n",
    "    def deleteFeatures(self, colCorr):\n",
    "        # Obtaining the feature to target correlation matrix dataframe\n",
    "        corrWithTarget = self.createCorrMatrixWithTarget()\n",
    "        for idx, row in corrWithTarget.iterrows():\n",
    "            #print(idx, '\\n')\n",
    "            if (idx in colCorr):\n",
    "                self.df = self.df.drop(idx, axis=1)\n",
    "                break\n",
    "        return self.df\n",
    "\n",
    "    # Method to run automatically eliminate multicollinearity\n",
    "    # Метод запускающий и удаляющий мультиколлинеарность\n",
    "    def autoEliminateMulticollinearity(self):\n",
    "        # Obtaining the list of correlated features\n",
    "        colCorr = self.createCorrelatedFeaturesList()\n",
    "        while colCorr != []:\n",
    "            # Obtaining the dataframe after deleting the feature (from the list of correlated features)\n",
    "            # that is least correlated with the taregt\n",
    "            self.df = self.deleteFeatures(colCorr)\n",
    "            # Obtaining the list of correlated features\n",
    "            colCorr = self.createCorrelatedFeaturesList()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1933cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_24272/3721317429.py:4: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = corr_explorer.autoEliminateMulticollinearity().drop(['target'],1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_24272/3721317429.py:6: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val = X_val.drop(X_val.columns.difference(X_train.columns),1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_24272/3721317429.py:7: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(X_test.columns.difference(X_train.columns),1)\n"
     ]
    }
   ],
   "source": [
    "# устраним скоррелированные признаки\n",
    "corr_explorer = MultiCollinearityEliminator(pd.concat([X_train, Y_train], axis=1), 'target', 0.75)\n",
    "\n",
    "X_train = corr_explorer.autoEliminateMulticollinearity().drop(['target'],1)\n",
    "\n",
    "X_val = X_val.drop(X_val.columns.difference(X_train.columns),1)\n",
    "X_test = X_test.drop(X_test.columns.difference(X_train.columns),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc36302e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: \t1 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t2 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t3 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t4 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t5 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t6 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t7 / 100\n",
      "Confirmed: \t0\n",
      "Tentative: \t75\n",
      "Rejected: \t0\n",
      "Iteration: \t8 / 100\n",
      "Confirmed: \t18\n",
      "Tentative: \t0\n",
      "Rejected: \t57\n",
      "\n",
      "\n",
      "BorutaPy finished running.\n",
      "\n",
      "Iteration: \t9 / 100\n",
      "Confirmed: \t18\n",
      "Tentative: \t0\n",
      "Rejected: \t57\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x25DE5AC1E40),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x25DE5AC1E40,\n",
       "         verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BorutaPy</label><div class=\"sk-toggleable__content\"><pre>BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x25DE5AC1E40),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x25DE5AC1E40,\n",
       "         verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=90, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x25DE5AC1E40)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, n_estimators=90, n_jobs=-1,\n",
       "                       random_state=RandomState(MT19937) at 0x25DE5AC1E40)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BorutaPy(estimator=RandomForestClassifier(max_depth=20, n_estimators=90,\n",
       "                                          n_jobs=-1,\n",
       "                                          random_state=RandomState(MT19937) at 0x25DE5AC1E40),\n",
       "         n_estimators=90, random_state=RandomState(MT19937) at 0x25DE5AC1E40,\n",
       "         verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_selector = BorutaPy(model, n_estimators=90, verbose=2)\n",
    "feat_selector.fit(X_train.values, Y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "81f94668",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = []\n",
    "un_selected_features = []\n",
    "for importance, col in list(zip(feat_selector.support_, X_train.columns)):\n",
    "    if importance == True:\n",
    "        selected_features.append(col)\n",
    "    else:\n",
    "        un_selected_features.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f020434c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2578391909.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2578391909.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_val.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_23464/2578391909.py:3: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test.drop(un_selected_features, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(un_selected_features, 1, inplace=True)\n",
    "X_val.drop(un_selected_features, 1, inplace=True)\n",
    "X_test.drop(un_selected_features, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039753c",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43defbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=11, n_estimators=180, tree_method='gpu_hist', n_jobs=-1, reg_lambda = 1, reg_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23292123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sample_weights(y):\n",
    "    weights = [abs(np.log((len(Y_train)-i)/i)) for i in list(Y_train.value_counts())]\n",
    "    temp = np.zeros(len(y))\n",
    "    for i in range(6):\n",
    "        temp[y == i] = weights[i]\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c810ae2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=1, ...)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, sample_weight=my_sample_weights(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "733989dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98     34863\n",
      "         1.0       0.95      0.80      0.87      2740\n",
      "         2.0       0.93      0.72      0.81       383\n",
      "         3.0       0.94      0.81      0.87       599\n",
      "         4.0       0.94      0.86      0.90       727\n",
      "         5.0       0.91      0.80      0.85       688\n",
      "\n",
      "    accuracy                           0.97     40000\n",
      "   macro avg       0.94      0.83      0.88     40000\n",
      "weighted avg       0.97      0.97      0.97     40000\n",
      "\n",
      "Метрика: 0.9203492957123587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# валидация + MultiCollinearityEliminator порог коллинеарности 0.75 + oversampling + sampling_strategy + svd2\n",
    "report = classification_report(Y_val, model.predict(X_val))\n",
    "print(report)\n",
    "print(f\"Метрика: {0.2* recall_score(Y_val, model.predict(X_val), average='macro') + 0.8* precision_score(Y_val, model.predict(X_val), average='macro')}\")\n",
    "\n",
    "# посмотрим как ошибается модель\n",
    "heat_map = np.zeros((6,6))\n",
    "for (y, y_pred) in zip(Y_val.values.astype(int), model.predict(X_val).astype(int)):\n",
    "    heat_map[y][y_pred] += 1\n",
    "sns.heatmap(heat_map, annot=True, cmap=\"gist_heat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f282f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00    139438\n",
      "         1.0       1.00      1.00      1.00     10772\n",
      "         2.0       1.00      1.00      1.00      1440\n",
      "         3.0       1.00      1.00      1.00      2428\n",
      "         4.0       1.00      1.00      1.00      2932\n",
      "         5.0       1.00      1.00      1.00      2990\n",
      "\n",
      "    accuracy                           1.00    160000\n",
      "   macro avg       1.00      1.00      1.00    160000\n",
      "weighted avg       1.00      1.00      1.00    160000\n",
      "\n",
      "Метрика: 0.999782798536406\n"
     ]
    }
   ],
   "source": [
    "# тренировочная выборка\n",
    "report = classification_report(Y_train, model.predict(X_train))\n",
    "print(report)\n",
    "print(f\"Метрика: {0.2* recall_score(Y_train, model.predict(X_train), average='macro') + 0.8* precision_score(Y_train, model.predict(X_train), average='macro')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091ab0d",
   "metadata": {},
   "source": [
    "# Sample solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c04bd295",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/2561632341.py:5: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = XY_train.drop(['target'], 1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/2561632341.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = XY_test.drop(['target'], 1)\n"
     ]
    }
   ],
   "source": [
    "# разделим выборки\n",
    "XY_train = train[train['train'] == 1].drop('train', axis=1)\n",
    "XY_test = train[train['train'] == 0].drop('train', axis=1)\n",
    "\n",
    "X_train = XY_train.drop(['target'], 1)\n",
    "Y_train = XY_train['target']\n",
    "\n",
    "X_test = XY_test.drop(['target'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2f6b7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorial_vars = ['program_id', 'student_id', 'communication_type', 'ABC', 'city', 'country', 'os', 'browser', \\\n",
    "                   'platform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abbfb12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/218761128.py:20: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  return X.drop(X_obj.columns,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/1999260008.py:8: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train = X_train.drop(categorial_vars,1)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/1999260008.py:9: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test = X_test.drop(categorial_vars,1)\n"
     ]
    }
   ],
   "source": [
    "one_hot_target_encoder = OneHotTargetEncoder()\n",
    "\n",
    "one_hot_target_encoder.fit(X_train[categorial_vars], Y_train)\n",
    "\n",
    "X_train = pd.concat([X_train, one_hot_target_encoder.transform(X_train[categorial_vars])], axis=1)\n",
    "X_test = pd.concat([X_test, one_hot_target_encoder.transform(X_test[categorial_vars])], axis=1)\n",
    "\n",
    "X_train = X_train.drop(categorial_vars,1)\n",
    "X_test = X_test.drop(categorial_vars,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f159ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/2153210587.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_train.drop(un_selected_features, 1, inplace=True)\n",
      "C:\\Users\\vanya\\AppData\\Local\\Temp/ipykernel_10616/2153210587.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  X_test.drop(un_selected_features, 1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_train.drop(un_selected_features, 1, inplace=True)\n",
    "X_test.drop(un_selected_features, 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30c6347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(max_depth=11, n_estimators=180, tree_method='gpu_hist', n_jobs=-1, reg_lambda = 1, reg_alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eb73c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy=&#x27;depthwise&#x27;,\n",
       "              importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;,\n",
       "              predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, gamma=0, gpu_id=0, grow_policy='depthwise',\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=11, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=180,\n",
       "              n_jobs=-1, num_parallel_tree=1, objective='multi:softprob',\n",
       "              predictor='auto', random_state=0, reg_alpha=1, ...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, sample_weight=my_sample_weights(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01b26ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution = pd.read_csv('sample_solution.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8dff1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution['target'] = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73b238f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution.to_csv('sample_solution_sas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21b8d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_solution_sas = pd.read_csv('sample_solution_sas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5580678f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77551</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>227812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103035</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260943</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134611</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84992</th>\n",
       "      <td>186427</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84993</th>\n",
       "      <td>197918</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84994</th>\n",
       "      <td>174961</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84995</th>\n",
       "      <td>182226</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84996</th>\n",
       "      <td>95178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  target\n",
       "0       77551       0\n",
       "1      227812       0\n",
       "2      103035       0\n",
       "3      260943       0\n",
       "4      134611       0\n",
       "...       ...     ...\n",
       "84992  186427       0\n",
       "84993  197918       0\n",
       "84994  174961       0\n",
       "84995  182226       0\n",
       "84996   95178       0\n",
       "\n",
       "[84997 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_solution_sas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
